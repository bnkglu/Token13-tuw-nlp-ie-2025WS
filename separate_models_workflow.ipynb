{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Separate Model Training and Evaluation Notebook"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load Data"]}, {"cell_type": "code", "metadata": {}, "source": ["import pandas as pd", "", "train_path = '/mnt/data/train_split.csv'", "val_path = '/mnt/data/val_split.csv'", "test_path = '/mnt/data/test_df.csv'", "", "text_col = \"text_with_markers\"", "target_col = \"label_id\"", "", "train_df = pd.read_csv(train_path)", "val_df = pd.read_csv(val_path)", "test_df = pd.read_csv(test_path)", "", "train_df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Vectorizer"]}, {"cell_type": "code", "metadata": {}, "source": ["from sklearn.feature_extraction.text import TfidfVectorizer", "", "vectorizer = TfidfVectorizer()", "X_train = vectorizer.fit_transform(train_df[text_col])", "y_train = train_df[target_col]", "", "X_val = vectorizer.transform(val_df[text_col])", "y_val = val_df[target_col]", "", "X_test = vectorizer.transform(test_df[text_col])", "y_test = test_df[target_col]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## SGD Logistic"]}, {"cell_type": "code", "metadata": {}, "source": ["from sklearn.linear_model import SGDClassifier", "model = SGDClassifier(loss='log_loss', random_state=42)", "", "model.fit(X_train, y_train)", "preds = model.predict(X_val)", "", "from sklearn.metrics import f1_score, confusion_matrix, classification_report", "", "macro_f1 = f1_score(y_val, preds, average='macro')", "", "labels = sorted(set(y_val))", "labels_wo_other = [l for l in labels if l != \"Other\"]", "macro_f1_wo_other = f1_score(y_val, preds, labels=labels_wo_other, average='macro')", "", "conf_mat = confusion_matrix(y_val, preds)", "report = classification_report(y_val, preds)", "", "print(\"Macro F1:\", macro_f1)", "print(\"Macro F1 (no 'Other'):\", macro_f1_wo_other)", "print(\"Confusion Matrix:\\n\", conf_mat)", "print(\"Report:\\n\", report)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## SGD SVM"]}, {"cell_type": "code", "metadata": {}, "source": ["from sklearn.linear_model import SGDClassifier", "model = SGDClassifier(loss='hinge', random_state=42)", "", "model.fit(X_train, y_train)", "preds = model.predict(X_val)", "", "from sklearn.metrics import f1_score, confusion_matrix, classification_report", "", "macro_f1 = f1_score(y_val, preds, average='macro')", "", "labels = sorted(set(y_val))", "labels_wo_other = [l for l in labels if l != \"Other\"]", "macro_f1_wo_other = f1_score(y_val, preds, labels=labels_wo_other, average='macro')", "", "conf_mat = confusion_matrix(y_val, preds)", "report = classification_report(y_val, preds)", "", "print(\"Macro F1:\", macro_f1)", "print(\"Macro F1 (no 'Other'):\", macro_f1_wo_other)", "print(\"Confusion Matrix:\\n\", conf_mat)", "print(\"Report:\\n\", report)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## MultinomialNB"]}, {"cell_type": "code", "metadata": {}, "source": ["from sklearn.naive_bayes import MultinomialNB", "model = MultinomialNB()", "", "model.fit(X_train, y_train)", "preds = model.predict(X_val)", "", "from sklearn.metrics import f1_score, confusion_matrix, classification_report", "", "macro_f1 = f1_score(y_val, preds, average='macro')", "", "labels = sorted(set(y_val))", "labels_wo_other = [l for l in labels if l != \"Other\"]", "macro_f1_wo_other = f1_score(y_val, preds, labels=labels_wo_other, average='macro')", "", "conf_mat = confusion_matrix(y_val, preds)", "report = classification_report(y_val, preds)", "", "print(\"Macro F1:\", macro_f1)", "print(\"Macro F1 (no 'Other'):\", macro_f1_wo_other)", "print(\"Confusion Matrix:\\n\", conf_mat)", "print(\"Report:\\n\", report)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Random Forest"]}, {"cell_type": "code", "metadata": {}, "source": ["from sklearn.ensemble import RandomForestClassifier", "model = RandomForestClassifier(n_estimators=200, random_state=42)", "", "model.fit(X_train, y_train)", "preds = model.predict(X_val)", "", "from sklearn.metrics import f1_score, confusion_matrix, classification_report", "", "macro_f1 = f1_score(y_val, preds, average='macro')", "", "labels = sorted(set(y_val))", "labels_wo_other = [l for l in labels if l != \"Other\"]", "macro_f1_wo_other = f1_score(y_val, preds, labels=labels_wo_other, average='macro')", "", "conf_mat = confusion_matrix(y_val, preds)", "report = classification_report(y_val, preds)", "", "print(\"Macro F1:\", macro_f1)", "print(\"Macro F1 (no 'Other'):\", macro_f1_wo_other)", "print(\"Confusion Matrix:\\n\", conf_mat)", "print(\"Report:\\n\", report)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Select Best Model & Evaluate on Test Set"]}, {"cell_type": "code", "metadata": {}, "source": ["# NOTE: After running above cells manually choose best model and evaluate here."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 5, "nbformat_minor": 5}