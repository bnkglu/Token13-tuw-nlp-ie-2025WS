{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Pipeline - SemEval 2010 Task 8\n",
    "\n",
    "## Overview\n",
    "This notebook implements the data preprocessing pipeline for the **SemEval 2010 Task 8** dataset:\n",
    "- **Task**: Multi-Way Classification of Semantic Relations Between Pairs of Nominals\n",
    "- **Dataset**: 8,000 training + 2,717 test sentences\n",
    "- **Relations**: 9 semantic relations + \"Other\" class = 19 labels (accounting for directionality)\n",
    "\n",
    "## Preprocessing Steps\n",
    "1. **Load Data**: Read raw text files from SemEval format\n",
    "2. **Parse Structure**: Extract sentence ID, text, entities (e1, e2), and labels\n",
    "3. **Clean Text**: Remove markup tags and normalize\n",
    "4. **Extract Components**: Separate entity mentions and context\n",
    "5. **Save Structured Data**: Store in CSV/JSON for downstream tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: /Users/egeaydin/Github/ML2025WS/Token13-tuw-nlp-ie-2025WS\n",
      "Train file exists: True\n",
      "Test file exists: True\n"
     ]
    }
   ],
   "source": [
    "# Base paths\n",
    "BASE_DIR = Path(\"../..\").resolve()\n",
    "RESOURCES_DIR = BASE_DIR / \"resources\" / \"SemEval2010_task8_all_data 2\"\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "\n",
    "# Input files\n",
    "TRAIN_FILE = RESOURCES_DIR / \"SemEval2010_task8_training\" / \"TRAIN_FILE.TXT\"\n",
    "TEST_FILE = RESOURCES_DIR / \"SemEval2010_task8_testing_keys\" / \"TEST_FILE_FULL.TXT\"\n",
    "TEST_KEY_FILE = RESOURCES_DIR / \"SemEval2010_task8_testing_keys\" / \"TEST_FILE_KEY.TXT\"\n",
    "\n",
    "# Output directories\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PREPROCESSED_DIR = DATA_DIR / \"preprocessed\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PREPROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Train file exists: {TRAIN_FILE.exists()}\")\n",
    "print(f\"Test file exists: {TEST_FILE.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Relation Types\n",
    "\n",
    "SemEval 2010 Task 8 includes 9 relation types. With directionality (e1,e2) and (e2,e1), we have 18 directed relations + \"Other\" = 19 total labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total relation types: 10\n",
      "Relations: Cause-Effect, Instrument-Agency, Product-Producer, Content-Container, Entity-Origin, Entity-Destination, Component-Whole, Member-Collection, Message-Topic, Other\n"
     ]
    }
   ],
   "source": [
    "# The 9 base semantic relations\n",
    "RELATIONS = [\n",
    "    \"Cause-Effect\",\n",
    "    \"Instrument-Agency\",\n",
    "    \"Product-Producer\",\n",
    "    \"Content-Container\",\n",
    "    \"Entity-Origin\",\n",
    "    \"Entity-Destination\",\n",
    "    \"Component-Whole\",\n",
    "    \"Member-Collection\",\n",
    "    \"Message-Topic\",\n",
    "    \"Other\"\n",
    "]\n",
    "\n",
    "print(f\"Total relation types: {len(RELATIONS)}\")\n",
    "print(f\"Relations: {', '.join(RELATIONS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Parser Functions\n",
    "\n",
    "### Parse SemEval Format\n",
    "The data format has 3-4 lines per example:\n",
    "- Line 1: `ID \"sentence with <e1>entity1</e1> and <e2>entity2</e2>\"`\n",
    "- Line 2: `Relation(e1,e2)` or `Other`\n",
    "- Line 3: `Comment: ...` (optional)\n",
    "- Blank line separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Parser functions defined\n"
     ]
    }
   ],
   "source": [
    "def parse_semeval_file(file_path: Path) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Parse SemEval 2010 Task 8 file format.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : Path\n",
    "        Path to the SemEval data file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Dict[str, str]]\n",
    "        List of parsed examples with keys: id, sentence, relation, comment\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        \n",
    "        # Skip empty lines\n",
    "        if not line:\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Parse sentence line: ID \"sentence\"\n",
    "        match = re.match(r'^(\\d+)\\s+\"(.+)\"$', line)\n",
    "        if match:\n",
    "            example_id = match.group(1)\n",
    "            sentence = match.group(2)\n",
    "            \n",
    "            # Get relation (next line)\n",
    "            i += 1\n",
    "            relation = lines[i].strip() if i < len(lines) else \"\"\n",
    "            \n",
    "            # Get comment if exists (next line)\n",
    "            i += 1\n",
    "            comment = \"\"\n",
    "            if i < len(lines) and lines[i].strip().startswith(\"Comment:\"):\n",
    "                comment = lines[i].strip().replace(\"Comment:\", \"\").strip()\n",
    "                i += 1\n",
    "            \n",
    "            examples.append({\n",
    "                \"id\": example_id,\n",
    "                \"sentence\": sentence,\n",
    "                \"relation\": relation,\n",
    "                \"comment\": comment\n",
    "            })\n",
    "        else:\n",
    "            i += 1\n",
    "    \n",
    "    return examples\n",
    "\n",
    "\n",
    "def extract_entities(sentence: str) -> Tuple[str, str, str]:\n",
    "    \"\"\"\n",
    "    Extract entities and clean sentence from markup.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence : str\n",
    "        Raw sentence with <e1> and <e2> tags\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[str, str, str]\n",
    "        (e1_text, e2_text, clean_sentence)\n",
    "    \"\"\"\n",
    "    # Extract entity 1\n",
    "    e1_match = re.search(r'<e1>(.+?)</e1>', sentence)\n",
    "    e1_text = e1_match.group(1) if e1_match else \"\"\n",
    "    \n",
    "    # Extract entity 2\n",
    "    e2_match = re.search(r'<e2>(.+?)</e2>', sentence)\n",
    "    e2_text = e2_match.group(1) if e2_match else \"\"\n",
    "    \n",
    "    # Clean sentence (remove tags)\n",
    "    clean_sentence = re.sub(r'</?e[12]>', '', sentence)\n",
    "    \n",
    "    return e1_text, e2_text, clean_sentence\n",
    "\n",
    "\n",
    "def parse_relation_label(relation: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Parse relation string into relation type and direction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    relation : str\n",
    "        Relation string like \"Cause-Effect(e1,e2)\" or \"Other\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[str, str]\n",
    "        (relation_type, direction) where direction is \"e1,e2\", \"e2,e1\", or \"none\"\n",
    "    \"\"\"\n",
    "    if relation == \"Other\":\n",
    "        return \"Other\", \"none\"\n",
    "    \n",
    "    # Match pattern: RelationType(e1,e2) or RelationType(e2,e1)\n",
    "    match = re.match(r'(.+)\\((e[12],e[12])\\)', relation)\n",
    "    if match:\n",
    "        relation_type = match.group(1)\n",
    "        direction = match.group(2)\n",
    "        return relation_type, direction\n",
    "    \n",
    "    return relation, \"unknown\"\n",
    "\n",
    "\n",
    "print(\"✓ Parser functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Parse Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing training data...\n",
      "Loaded 8000 training examples\n",
      "\n",
      "First training example:\n",
      "ID: 1\n",
      "Sentence: The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\n",
      "Relation: Component-Whole(e2,e1)\n",
      "Comment: Not a collection: there is structure here, organisation.\n"
     ]
    }
   ],
   "source": [
    "# Parse training file\n",
    "print(\"Parsing training data...\")\n",
    "train_examples = parse_semeval_file(TRAIN_FILE)\n",
    "print(f\"Loaded {len(train_examples)} training examples\")\n",
    "\n",
    "# Show first example\n",
    "if train_examples:\n",
    "    print(\"\\nFirst training example:\")\n",
    "    print(f\"ID: {train_examples[0]['id']}\")\n",
    "    print(f\"Sentence: {train_examples[0]['sentence']}\")\n",
    "    print(f\"Relation: {train_examples[0]['relation']}\")\n",
    "    print(f\"Comment: {train_examples[0]['comment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load and Parse Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing test data...\n",
      "Loaded 2717 test examples\n",
      "\n",
      "First test example:\n",
      "ID: 8001\n",
      "Sentence: The most common <e1>audits</e1> were about <e2>waste</e2> and recycling.\n",
      "Relation: Message-Topic(e1,e2)\n",
      "Comment: Assuming an audit = an audit document.\n"
     ]
    }
   ],
   "source": [
    "# Parse test file\n",
    "print(\"Parsing test data...\")\n",
    "test_examples = parse_semeval_file(TEST_FILE)\n",
    "print(f\"Loaded {len(test_examples)} test examples\")\n",
    "\n",
    "# Show first example\n",
    "if test_examples:\n",
    "    print(\"\\nFirst test example:\")\n",
    "    print(f\"ID: {test_examples[0]['id']}\")\n",
    "    print(f\"Sentence: {test_examples[0]['sentence']}\")\n",
    "    print(f\"Relation: {test_examples[0]['relation']}\")\n",
    "    print(f\"Comment: {test_examples[0]['comment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Process and Structure Data\n",
    "\n",
    "Extract entities and create structured records for each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training examples...\n",
      "Processed 8000 training examples\n",
      "\n",
      "Processing test examples...\n",
      "Processed 2717 test examples\n",
      "\n",
      "Sample processed training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence_raw</th>\n",
       "      <th>sentence_clean</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>relation_full</th>\n",
       "      <th>relation_type</th>\n",
       "      <th>relation_direction</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The system as described above has its greatest...</td>\n",
       "      <td>The system as described above has its greatest...</td>\n",
       "      <td>configuration</td>\n",
       "      <td>elements</td>\n",
       "      <td>Component-Whole(e2,e1)</td>\n",
       "      <td>Component-Whole</td>\n",
       "      <td>e2,e1</td>\n",
       "      <td>Not a collection: there is structure here, org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The &lt;e1&gt;child&lt;/e1&gt; was carefully wrapped and b...</td>\n",
       "      <td>The child was carefully wrapped and bound into...</td>\n",
       "      <td>child</td>\n",
       "      <td>cradle</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>none</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The &lt;e1&gt;author&lt;/e1&gt; of a keygen uses a &lt;e2&gt;dis...</td>\n",
       "      <td>The author of a keygen uses a disassembler to ...</td>\n",
       "      <td>author</td>\n",
       "      <td>disassembler</td>\n",
       "      <td>Instrument-Agency(e2,e1)</td>\n",
       "      <td>Instrument-Agency</td>\n",
       "      <td>e2,e1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                       sentence_raw  \\\n",
       "0   1  The system as described above has its greatest...   \n",
       "1   2  The <e1>child</e1> was carefully wrapped and b...   \n",
       "2   3  The <e1>author</e1> of a keygen uses a <e2>dis...   \n",
       "\n",
       "                                      sentence_clean             e1  \\\n",
       "0  The system as described above has its greatest...  configuration   \n",
       "1  The child was carefully wrapped and bound into...          child   \n",
       "2  The author of a keygen uses a disassembler to ...         author   \n",
       "\n",
       "             e2             relation_full      relation_type  \\\n",
       "0      elements    Component-Whole(e2,e1)    Component-Whole   \n",
       "1        cradle                     Other              Other   \n",
       "2  disassembler  Instrument-Agency(e2,e1)  Instrument-Agency   \n",
       "\n",
       "  relation_direction                                            comment  \n",
       "0              e2,e1  Not a collection: there is structure here, org...  \n",
       "1               none                                                     \n",
       "2              e2,e1                                                     "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_examples(examples: List[Dict[str, str]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process raw examples into structured DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    examples : List[Dict[str, str]]\n",
    "        Raw parsed examples\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Structured DataFrame with all extracted features\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "    \n",
    "    for ex in examples:\n",
    "        # Extract entities\n",
    "        e1_text, e2_text, clean_sent = extract_entities(ex[\"sentence\"])\n",
    "        \n",
    "        # Parse relation\n",
    "        relation_type, direction = parse_relation_label(ex[\"relation\"])\n",
    "        \n",
    "        processed_data.append({\n",
    "            \"id\": int(ex[\"id\"]),\n",
    "            \"sentence_raw\": ex[\"sentence\"],\n",
    "            \"sentence_clean\": clean_sent,\n",
    "            \"e1\": e1_text,\n",
    "            \"e2\": e2_text,\n",
    "            \"relation_full\": ex[\"relation\"],\n",
    "            \"relation_type\": relation_type,\n",
    "            \"relation_direction\": direction,\n",
    "            \"comment\": ex[\"comment\"]\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(processed_data)\n",
    "\n",
    "\n",
    "# Process training data\n",
    "print(\"Processing training examples...\")\n",
    "train_df = process_examples(train_examples)\n",
    "print(f\"Processed {len(train_df)} training examples\")\n",
    "\n",
    "# Process test data\n",
    "print(\"\\nProcessing test examples...\")\n",
    "test_df = process_examples(test_examples)\n",
    "print(f\"Processed {len(test_df)} test examples\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample processed training data:\")\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Statistics and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Dataset Statistics\n",
      "============================================================\n",
      "\n",
      "Total examples: 8000\n",
      "\n",
      "Columns: ['id', 'sentence_raw', 'sentence_clean', 'e1', 'e2', 'relation_full', 'relation_type', 'relation_direction', 'comment']\n",
      "\n",
      "Relation Type Distribution:\n",
      "----------------------------------------\n",
      "Other                    : 1410 (17.62%)\n",
      "Cause-Effect             : 1003 (12.54%)\n",
      "Component-Whole          :  941 (11.76%)\n",
      "Entity-Destination       :  845 (10.56%)\n",
      "Product-Producer         :  717 ( 8.96%)\n",
      "Entity-Origin            :  716 ( 8.95%)\n",
      "Member-Collection        :  690 ( 8.62%)\n",
      "Message-Topic            :  634 ( 7.92%)\n",
      "Content-Container        :  540 ( 6.75%)\n",
      "Instrument-Agency        :  504 ( 6.30%)\n",
      "\n",
      "Relation Direction Distribution (non-Other):\n",
      "----------------------------------------\n",
      "e1,e2     : 3588 (54.45%)\n",
      "e2,e1     : 3002 (45.55%)\n",
      "\n",
      "Top 10 Full Relation Labels:\n",
      "----------------------------------------\n",
      "Other                         : 1410\n",
      "Entity-Destination(e1,e2)     :  844\n",
      "Cause-Effect(e2,e1)           :  659\n",
      "Member-Collection(e2,e1)      :  612\n",
      "Entity-Origin(e1,e2)          :  568\n",
      "Message-Topic(e1,e2)          :  490\n",
      "Component-Whole(e2,e1)        :  471\n",
      "Component-Whole(e1,e2)        :  470\n",
      "Instrument-Agency(e2,e1)      :  407\n",
      "Product-Producer(e2,e1)       :  394\n",
      "\n",
      "Entity Statistics:\n",
      "----------------------------------------\n",
      "Average e1 length: 6.89 characters\n",
      "Average e2 length: 7.15 characters\n",
      "Average sentence length: 101.79 characters\n",
      "\n",
      "Missing Values:\n",
      "----------------------------------------\n",
      "No missing values!\n",
      "\n",
      "============================================================\n",
      "Test Dataset Statistics\n",
      "============================================================\n",
      "\n",
      "Total examples: 2717\n",
      "\n",
      "Columns: ['id', 'sentence_raw', 'sentence_clean', 'e1', 'e2', 'relation_full', 'relation_type', 'relation_direction', 'comment']\n",
      "\n",
      "Relation Type Distribution:\n",
      "----------------------------------------\n",
      "Other                    :  454 (16.71%)\n",
      "Cause-Effect             :  328 (12.07%)\n",
      "Component-Whole          :  312 (11.48%)\n",
      "Entity-Destination       :  292 (10.75%)\n",
      "Message-Topic            :  261 ( 9.61%)\n",
      "Entity-Origin            :  258 ( 9.50%)\n",
      "Member-Collection        :  233 ( 8.58%)\n",
      "Product-Producer         :  231 ( 8.50%)\n",
      "Content-Container        :  192 ( 7.07%)\n",
      "Instrument-Agency        :  156 ( 5.74%)\n",
      "\n",
      "Relation Direction Distribution (non-Other):\n",
      "----------------------------------------\n",
      "e1,e2     : 1323 (58.46%)\n",
      "e2,e1     :  940 (41.54%)\n",
      "\n",
      "Top 10 Full Relation Labels:\n",
      "----------------------------------------\n",
      "Other                         :  454\n",
      "Entity-Destination(e1,e2)     :  291\n",
      "Entity-Origin(e1,e2)          :  211\n",
      "Message-Topic(e1,e2)          :  210\n",
      "Member-Collection(e2,e1)      :  201\n",
      "Cause-Effect(e2,e1)           :  194\n",
      "Component-Whole(e1,e2)        :  162\n",
      "Content-Container(e1,e2)      :  153\n",
      "Component-Whole(e2,e1)        :  150\n",
      "Instrument-Agency(e2,e1)      :  134\n",
      "\n",
      "Entity Statistics:\n",
      "----------------------------------------\n",
      "Average e1 length: 6.71 characters\n",
      "Average e2 length: 7.02 characters\n",
      "Average sentence length: 101.42 characters\n",
      "\n",
      "Missing Values:\n",
      "----------------------------------------\n",
      "No missing values!\n"
     ]
    }
   ],
   "source": [
    "def print_data_statistics(df: pd.DataFrame, dataset_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Print comprehensive statistics about the dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Processed dataset\n",
    "    dataset_name : str\n",
    "        Name of the dataset (e.g., \"Training\", \"Test\")\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{dataset_name} Dataset Statistics\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\nTotal examples: {len(df)}\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    \n",
    "    # Relation distribution\n",
    "    print(f\"\\nRelation Type Distribution:\")\n",
    "    print(\"-\" * 40)\n",
    "    relation_counts = df[\"relation_type\"].value_counts()\n",
    "    for rel, count in relation_counts.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"{rel:25s}: {count:4d} ({percentage:5.2f}%)\")\n",
    "    \n",
    "    # Direction distribution (excluding \"Other\")\n",
    "    print(f\"\\nRelation Direction Distribution (non-Other):\")\n",
    "    print(\"-\" * 40)\n",
    "    non_other = df[df[\"relation_type\"] != \"Other\"]\n",
    "    if len(non_other) > 0:\n",
    "        direction_counts = non_other[\"relation_direction\"].value_counts()\n",
    "        for direction, count in direction_counts.items():\n",
    "            percentage = (count / len(non_other)) * 100\n",
    "            print(f\"{direction:10s}: {count:4d} ({percentage:5.2f}%)\")\n",
    "    \n",
    "    # Full relation label distribution\n",
    "    print(f\"\\nTop 10 Full Relation Labels:\")\n",
    "    print(\"-\" * 40)\n",
    "    full_rel_counts = df[\"relation_full\"].value_counts().head(10)\n",
    "    for rel, count in full_rel_counts.items():\n",
    "        print(f\"{rel:30s}: {count:4d}\")\n",
    "    \n",
    "    # Entity statistics\n",
    "    print(f\"\\nEntity Statistics:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Average e1 length: {df['e1'].str.len().mean():.2f} characters\")\n",
    "    print(f\"Average e2 length: {df['e2'].str.len().mean():.2f} characters\")\n",
    "    print(f\"Average sentence length: {df['sentence_clean'].str.len().mean():.2f} characters\")\n",
    "    \n",
    "    # Missing values\n",
    "    print(f\"\\nMissing Values:\")\n",
    "    print(\"-\" * 40)\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() == 0:\n",
    "        print(\"No missing values!\")\n",
    "    else:\n",
    "        print(missing[missing > 0])\n",
    "\n",
    "\n",
    "# Print statistics\n",
    "print_data_statistics(train_df, \"Training\")\n",
    "print_data_statistics(test_df, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Preprocessed Data\n",
    "\n",
    "Save the structured data in multiple formats:\n",
    "- **CSV**: Easy to read with pandas, good for tabular data\n",
    "- **JSON**: Hierarchical structure, good for nested data\n",
    "- **Parquet**: Efficient binary format (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training data saved:\n",
      "  - CSV: /Users/egeaydin/Github/ML2025WS/Token13-tuw-nlp-ie-2025WS/data/preprocessed/train.csv\n",
      "  - JSON: /Users/egeaydin/Github/ML2025WS/Token13-tuw-nlp-ie-2025WS/data/preprocessed/train.json\n",
      "\n",
      "✓ Test data saved:\n",
      "  - CSV: /Users/egeaydin/Github/ML2025WS/Token13-tuw-nlp-ie-2025WS/data/preprocessed/test.csv\n",
      "  - JSON: /Users/egeaydin/Github/ML2025WS/Token13-tuw-nlp-ie-2025WS/data/preprocessed/test.json\n",
      "\n",
      "✓ Metadata saved: /Users/egeaydin/Github/ML2025WS/Token13-tuw-nlp-ie-2025WS/data/preprocessed/metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Save training data\n",
    "train_csv_path = PREPROCESSED_DIR / \"train.csv\"\n",
    "train_json_path = PREPROCESSED_DIR / \"train.json\"\n",
    "\n",
    "train_df.to_csv(train_csv_path, index=False)\n",
    "train_df.to_json(train_json_path, orient=\"records\", indent=2)\n",
    "\n",
    "print(f\"✓ Training data saved:\")\n",
    "print(f\"  - CSV: {train_csv_path}\")\n",
    "print(f\"  - JSON: {train_json_path}\")\n",
    "\n",
    "# Save test data\n",
    "test_csv_path = PREPROCESSED_DIR / \"test.csv\"\n",
    "test_json_path = PREPROCESSED_DIR / \"test.json\"\n",
    "\n",
    "test_df.to_csv(test_csv_path, index=False)\n",
    "test_df.to_json(test_json_path, orient=\"records\", indent=2)\n",
    "\n",
    "print(f\"\\n✓ Test data saved:\")\n",
    "print(f\"  - CSV: {test_csv_path}\")\n",
    "print(f\"  - JSON: {test_json_path}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    \"dataset\": \"SemEval 2010 Task 8\",\n",
    "    \"task\": \"Multi-Way Classification of Semantic Relations Between Pairs of Nominals\",\n",
    "    \"train_size\": len(train_df),\n",
    "    \"test_size\": len(test_df),\n",
    "    \"num_relations\": len(RELATIONS),\n",
    "    \"relations\": RELATIONS,\n",
    "    \"columns\": list(train_df.columns)\n",
    "}\n",
    "\n",
    "metadata_path = PREPROCESSED_DIR / \"metadata.json\"\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Metadata saved: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Validation: Load and Verify Saved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n",
      "----------------------------------------\n",
      "✓ Training data loaded: 8000 examples\n",
      "✓ Test data loaded: 2717 examples\n",
      "✓ Data integrity check: True\n",
      "\n",
      "Sample from loaded training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence_raw</th>\n",
       "      <th>sentence_clean</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>relation_full</th>\n",
       "      <th>relation_type</th>\n",
       "      <th>relation_direction</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The system as described above has its greatest...</td>\n",
       "      <td>The system as described above has its greatest...</td>\n",
       "      <td>configuration</td>\n",
       "      <td>elements</td>\n",
       "      <td>Component-Whole(e2,e1)</td>\n",
       "      <td>Component-Whole</td>\n",
       "      <td>e2,e1</td>\n",
       "      <td>Not a collection: there is structure here, org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The &lt;e1&gt;child&lt;/e1&gt; was carefully wrapped and b...</td>\n",
       "      <td>The child was carefully wrapped and bound into...</td>\n",
       "      <td>child</td>\n",
       "      <td>cradle</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The &lt;e1&gt;author&lt;/e1&gt; of a keygen uses a &lt;e2&gt;dis...</td>\n",
       "      <td>The author of a keygen uses a disassembler to ...</td>\n",
       "      <td>author</td>\n",
       "      <td>disassembler</td>\n",
       "      <td>Instrument-Agency(e2,e1)</td>\n",
       "      <td>Instrument-Agency</td>\n",
       "      <td>e2,e1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                       sentence_raw  \\\n",
       "0   1  The system as described above has its greatest...   \n",
       "1   2  The <e1>child</e1> was carefully wrapped and b...   \n",
       "2   3  The <e1>author</e1> of a keygen uses a <e2>dis...   \n",
       "\n",
       "                                      sentence_clean             e1  \\\n",
       "0  The system as described above has its greatest...  configuration   \n",
       "1  The child was carefully wrapped and bound into...          child   \n",
       "2  The author of a keygen uses a disassembler to ...         author   \n",
       "\n",
       "             e2             relation_full      relation_type  \\\n",
       "0      elements    Component-Whole(e2,e1)    Component-Whole   \n",
       "1        cradle                     Other              Other   \n",
       "2  disassembler  Instrument-Agency(e2,e1)  Instrument-Agency   \n",
       "\n",
       "  relation_direction                                            comment  \n",
       "0              e2,e1  Not a collection: there is structure here, org...  \n",
       "1               none                                                NaN  \n",
       "2              e2,e1                                                NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load saved data\n",
    "train_loaded = pd.read_csv(train_csv_path)\n",
    "test_loaded = pd.read_csv(test_csv_path)\n",
    "\n",
    "print(\"Validation Results:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"✓ Training data loaded: {len(train_loaded)} examples\")\n",
    "print(f\"✓ Test data loaded: {len(test_loaded)} examples\")\n",
    "print(f\"✓ Data integrity check: {len(train_loaded) == len(train_df) and len(test_loaded) == len(test_df)}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample from loaded training data:\")\n",
    "train_loaded.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Completed Data Preprocessing Steps:**\n",
    "1. Loaded SemEval 2010 Task 8 raw data files\n",
    "2. Parsed structured format (ID, sentence, relation, comment)\n",
    "3. Extracted entity mentions (e1, e2) and removed markup tags\n",
    "4. Separated relation type and directionality\n",
    "5. Generated clean sentences and structured features\n",
    "6. Saved preprocessed data in CSV and JSON formats\n",
    "7. Validated data integrity\n",
    "\n",
    "**Output Files:**\n",
    "- `data/preprocessed/train.csv` - Training data (8,000 examples)\n",
    "- `data/preprocessed/test.csv` - Test data (2,717 examples)\n",
    "- `data/preprocessed/train.json` - Training data (JSON format)\n",
    "- `data/preprocessed/test.json` - Test data (JSON format)\n",
    "- `data/preprocessed/metadata.json` - Dataset metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
