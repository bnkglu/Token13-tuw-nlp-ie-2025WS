{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad42ae1",
   "metadata": {},
   "source": [
    "### Explore Rule Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86d0f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e863f448",
   "metadata": {},
   "source": [
    "#### Exploration over single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3aebae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu\n",
    "import re\n",
    "\n",
    "def parse_conllu_file(filepath: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Parse CoNLL-U file into structured examples using conllu library.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = conllu.parse(f.read())\n",
    "    \n",
    "    examples = []\n",
    "    for sent in data:\n",
    "        example = sent.metadata.copy()\n",
    "        \n",
    "        tokens = []\n",
    "        for t in sent:\n",
    "            token = {\n",
    "                \"id\": str(t[\"id\"]),\n",
    "                \"form\": t[\"form\"],\n",
    "                \"lemma\": t[\"lemma\"],\n",
    "                \"upos\": t[\"upos\"],\n",
    "                \"xpos\": t[\"xpos\"],\n",
    "                \"feats\": t[\"feats\"] if t[\"feats\"] else \"_\",\n",
    "                \"head\": str(t[\"head\"]),\n",
    "                \"deprel\": t[\"deprel\"],\n",
    "                \"entity\": None\n",
    "            }\n",
    "            \n",
    "            if t[\"feats\"]:\n",
    "                feats_str = \"|\".join([f\"{k}={v}\" for k, v in t[\"feats\"].items()])\n",
    "                token[\"feats\"] = feats_str\n",
    "            \n",
    "            if t[\"misc\"] and \"Entity\" in t[\"misc\"]:\n",
    "                token[\"entity\"] = f\"Entity={t['misc']['Entity']}\"\n",
    "            \n",
    "            tokens.append(token)\n",
    "        example[\"tokens\"] = tokens\n",
    "        \n",
    "        # Post-process e1 and e2 positions from metadata\n",
    "        for key in [\"e1\", \"e2\"]:\n",
    "            if key in example:\n",
    "                val = example[key]\n",
    "                match = re.match(r\"(.+?)\\s+\\[(\\d+):(\\d+)\\]\", val)\n",
    "                if match:\n",
    "                    word, start, end = match.groups()\n",
    "                    example[key] = {\n",
    "                        \"text\": word,\n",
    "                        \"start\": int(start),\n",
    "                        \"end\": int(end)\n",
    "                    }\n",
    "        examples.append(example)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f55de468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data_path = \"../../../data/processed/train/train.conllu\"\n",
    "train_examples = parse_conllu_file(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e99632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:\n",
      "The system as described above has its greatest application in an arrayed configuration of antenna elements.\n",
      "\n",
      "Relation: Component-Whole(e2,e1)\n",
      "\n",
      "Entity 1:\n",
      "{'text': 'configuration', 'start': 12, 'end': 13}\n",
      "\n",
      "Entity 2:\n",
      "{'text': 'elements', 'start': 15, 'end': 16}\n"
     ]
    }
   ],
   "source": [
    "ex = train_examples[0]\n",
    "\n",
    "print(\"Sentence:\")\n",
    "print(ex[\"text\"])\n",
    "print(\"\\nRelation:\", ex[\"relation\"])\n",
    "\n",
    "print(\"\\nEntity 1:\")\n",
    "print(ex[\"e1\"])\n",
    "\n",
    "print(\"\\nEntity 2:\")\n",
    "print(ex[\"e2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd29c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>feats</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Definite=Def|PronType=Art</td>\n",
       "      <td>2</td>\n",
       "      <td>det</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>system</td>\n",
       "      <td>system</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>6</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>as</td>\n",
       "      <td>as</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>mark</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>described</td>\n",
       "      <td>describe</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>Aspect=Perf|Tense=Past|VerbForm=Part</td>\n",
       "      <td>2</td>\n",
       "      <td>advcl</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>above</td>\n",
       "      <td>above</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>advmod</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>has</td>\n",
       "      <td>have</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...</td>\n",
       "      <td>0</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>its</td>\n",
       "      <td>its</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>Gender=Neut|Number=Sing|Person=3|Poss=Yes|Pron...</td>\n",
       "      <td>9</td>\n",
       "      <td>poss</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>greatest</td>\n",
       "      <td>great</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJS</td>\n",
       "      <td>Degree=Sup</td>\n",
       "      <td>9</td>\n",
       "      <td>amod</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>application</td>\n",
       "      <td>application</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>6</td>\n",
       "      <td>dobj</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>9</td>\n",
       "      <td>prep</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>an</td>\n",
       "      <td>an</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Definite=Ind|PronType=Art</td>\n",
       "      <td>13</td>\n",
       "      <td>det</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>arrayed</td>\n",
       "      <td>array</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>Aspect=Perf|Tense=Past|VerbForm=Part</td>\n",
       "      <td>13</td>\n",
       "      <td>amod</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>configuration</td>\n",
       "      <td>configuration</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>10</td>\n",
       "      <td>pobj</td>\n",
       "      <td>Entity=e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>13</td>\n",
       "      <td>prep</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>antenna</td>\n",
       "      <td>antenna</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>16</td>\n",
       "      <td>compound</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>elements</td>\n",
       "      <td>element</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Number=Plur</td>\n",
       "      <td>14</td>\n",
       "      <td>pobj</td>\n",
       "      <td>Entity=e2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>PunctType=Peri</td>\n",
       "      <td>6</td>\n",
       "      <td>punct</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id           form          lemma   upos  xpos  \\\n",
       "0    1            The            the    DET    DT   \n",
       "1    2         system         system   NOUN    NN   \n",
       "2    3             as             as  SCONJ    IN   \n",
       "3    4      described       describe   VERB   VBN   \n",
       "4    5          above          above    ADV    RB   \n",
       "5    6            has           have   VERB   VBZ   \n",
       "6    7            its            its   PRON  PRP$   \n",
       "7    8       greatest          great    ADJ   JJS   \n",
       "8    9    application    application   NOUN    NN   \n",
       "9   10             in             in    ADP    IN   \n",
       "10  11             an             an    DET    DT   \n",
       "11  12        arrayed          array   VERB   VBN   \n",
       "12  13  configuration  configuration   NOUN    NN   \n",
       "13  14             of             of    ADP    IN   \n",
       "14  15        antenna        antenna   NOUN    NN   \n",
       "15  16       elements        element   NOUN   NNS   \n",
       "16  17              .              .  PUNCT     .   \n",
       "\n",
       "                                                feats head    deprel  \\\n",
       "0                           Definite=Def|PronType=Art    2       det   \n",
       "1                                         Number=Sing    6     nsubj   \n",
       "2                                                   _    4      mark   \n",
       "3                Aspect=Perf|Tense=Past|VerbForm=Part    2     advcl   \n",
       "4                                                   _    4    advmod   \n",
       "5   Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...    0      ROOT   \n",
       "6   Gender=Neut|Number=Sing|Person=3|Poss=Yes|Pron...    9      poss   \n",
       "7                                          Degree=Sup    9      amod   \n",
       "8                                         Number=Sing    6      dobj   \n",
       "9                                                   _    9      prep   \n",
       "10                          Definite=Ind|PronType=Art   13       det   \n",
       "11               Aspect=Perf|Tense=Past|VerbForm=Part   13      amod   \n",
       "12                                        Number=Sing   10      pobj   \n",
       "13                                                  _   13      prep   \n",
       "14                                        Number=Sing   16  compound   \n",
       "15                                        Number=Plur   14      pobj   \n",
       "16                                     PunctType=Peri    6     punct   \n",
       "\n",
       "       entity  \n",
       "0        None  \n",
       "1        None  \n",
       "2        None  \n",
       "3        None  \n",
       "4        None  \n",
       "5        None  \n",
       "6        None  \n",
       "7        None  \n",
       "8        None  \n",
       "9        None  \n",
       "10       None  \n",
       "11       None  \n",
       "12  Entity=e1  \n",
       "13       None  \n",
       "14       None  \n",
       "15  Entity=e2  \n",
       "16       None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(ex[\"tokens\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3512b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "from IPython.display import HTML\n",
    "\n",
    "def visualize_conllu_dependency(example):\n",
    "    \"\"\"\n",
    "    Create a displaCy visualization from a CoNLL-U parsed example\n",
    "    without re-parsing with spaCy.\n",
    "    \"\"\"\n",
    "    tokens = example[\"tokens\"]\n",
    "\n",
    "    # Build nodes\n",
    "    words = []\n",
    "    arcs = []\n",
    "\n",
    "    for t in tokens:\n",
    "        tid = int(t[\"id\"])\n",
    "        head = int(t[\"head\"])\n",
    "        dep = t[\"deprel\"]\n",
    "\n",
    "        words.append({\"text\": t[\"form\"], \"tag\": t[\"upos\"]})\n",
    "\n",
    "        # Skip ROOT (head = 0)\n",
    "        if head != 0:\n",
    "            start = min(tid - 1, head - 1)\n",
    "            end = max(tid - 1, head - 1)\n",
    "\n",
    "            arcs.append({\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "                \"label\": dep,\n",
    "                \"dir\": \"left\" if head < tid else \"right\"\n",
    "            })\n",
    "\n",
    "    # displacy expects this dict\n",
    "    dep_doc = {\n",
    "        \"words\": words,\n",
    "        \"arcs\": arcs\n",
    "    }\n",
    "\n",
    "    # Render inline HTML\n",
    "    html = displacy.render(dep_doc, style=\"dep\", manual=True, jupyter=False)\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8219a305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9c3d8e872d7f461282f85ebcba2f7908-0\" class=\"displacy\" width=\"3025\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">system</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">as</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">described</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">above</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">has</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">its</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">greatest</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">application</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">an</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">arrayed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">configuration</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">antenna</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">elements</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">PUNCT</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M210.0,354.0 L218.0,342.0 202.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,89.5 920.0,89.5 920.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,354.0 L928.0,342.0 912.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M560.0,354.0 L568.0,342.0 552.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-3\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-4\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,177.0 1440.0,177.0 1440.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1440.0,354.0 L1448.0,342.0 1432.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1435.0,354.0 L1443.0,342.0 1427.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-7\" stroke-width=\"2px\" d=\"M945,352.0 C945,89.5 1445.0,89.5 1445.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-8\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,354.0 L1462,342.0 1478,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,177.0 2140.0,177.0 2140.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2140.0,354.0 L2148.0,342.0 2132.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-10\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,264.5 2135.0,264.5 2135.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2135.0,354.0 L2143.0,342.0 2127.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-11\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,89.5 2145.0,89.5 2145.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-12\" stroke-width=\"2px\" d=\"M2170,352.0 C2170,264.5 2310.0,264.5 2310.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2170,354.0 L2162,342.0 2178,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-13\" stroke-width=\"2px\" d=\"M2520,352.0 C2520,264.5 2660.0,264.5 2660.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2660.0,354.0 L2668.0,342.0 2652.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-14\" stroke-width=\"2px\" d=\"M2345,352.0 C2345,177.0 2665.0,177.0 2665.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2345,354.0 L2337,342.0 2353,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9c3d8e872d7f461282f85ebcba2f7908-0-15\" stroke-width=\"2px\" d=\"M945,352.0 C945,2.0 2850.0,2.0 2850.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9c3d8e872d7f461282f85ebcba2f7908-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_conllu_dependency(train_examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ee2248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1 id: 13 → configuration\n",
      "e2 id: 16 → elements\n"
     ]
    }
   ],
   "source": [
    "def find_entities(example):\n",
    "    e1_pos = None\n",
    "    e2_pos = None\n",
    "    \n",
    "    for tok in example[\"tokens\"]:\n",
    "        if tok[\"entity\"] == \"Entity=e1\":\n",
    "            e1_pos = int(tok[\"id\"])\n",
    "        if tok[\"entity\"] == \"Entity=e2\":\n",
    "            e2_pos = int(tok[\"id\"])\n",
    "    \n",
    "    return e1_pos, e2_pos\n",
    "\n",
    "e1_id, e2_id = find_entities(ex)\n",
    "print(\"e1 id:\", e1_id, \"→\", ex[\"tokens\"][e1_id-1][\"form\"])\n",
    "print(\"e2 id:\", e2_id, \"→\", ex[\"tokens\"][e2_id-1][\"form\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "736f1455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDP (token ids): [13, 14, 16]\n",
      "\n",
      "SDP (tokens): ['configuration', 'of', 'elements']\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "def shortest_dep_path(example, start, end):\n",
    "    # Build undirected adjacency from dependency edges\n",
    "    graph = defaultdict(list)\n",
    "    for tok in example[\"tokens\"]:\n",
    "        tid = int(tok[\"id\"])\n",
    "        head = int(tok[\"head\"])\n",
    "        if head != 0:  # skip ROOT\n",
    "            graph[tid].append(head)\n",
    "            graph[head].append(tid)\n",
    "\n",
    "    # BFS shortest path\n",
    "    queue = deque([(start, [start])])\n",
    "    visited = set([start])\n",
    "    while queue:\n",
    "        node, path = queue.popleft()\n",
    "        if node == end:\n",
    "            return path\n",
    "        for neigh in graph[node]:\n",
    "            if neigh not in visited:\n",
    "                visited.add(neigh)\n",
    "                queue.append((neigh, path + [neigh]))\n",
    "    return None\n",
    "\n",
    "path_ids = shortest_dep_path(ex, e1_id, e2_id)\n",
    "print(\"SDP (token ids):\", path_ids)\n",
    "\n",
    "print(\"\\nSDP (tokens):\", [ex[\"tokens\"][i-1][\"form\"] for i in path_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ad497bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prep', 'down (head→child)'), ('pobj', 'down (head→child)')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_deprels(example, path_ids):\n",
    "    tlist = example[\"tokens\"]\n",
    "    labels = []\n",
    "    for i in range(len(path_ids)-1):\n",
    "        a, b = path_ids[i], path_ids[i+1]\n",
    "\n",
    "        # check both directions (because we built undirected graph)\n",
    "        tok_a = tlist[a-1]\n",
    "        tok_b = tlist[b-1]\n",
    "\n",
    "        if int(tok_a[\"head\"]) == b:\n",
    "            labels.append((tok_a[\"deprel\"], \"up (child→head)\"))\n",
    "        elif int(tok_b[\"head\"]) == a:\n",
    "            labels.append((tok_b[\"deprel\"], \"down (head→child)\"))\n",
    "        else:\n",
    "            labels.append((\"unknown\", \"???\"))\n",
    "    return labels\n",
    "\n",
    "labels = get_deprels(ex, path_ids)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b26a556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full SDP explanation:\n",
      "\n",
      "13:configuration (pobj)\n",
      "   │\n",
      "   ↓\n",
      "14:of (prep)\n",
      "   │\n",
      "   ↓\n",
      "16:elements (pobj)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFull SDP explanation:\\n\")\n",
    "tokens = ex[\"tokens\"]\n",
    "for i in range(len(path_ids)):\n",
    "    tid = path_ids[i]\n",
    "    t = tokens[tid-1]\n",
    "    print(f\"{tid}:{t['form']} ({t['deprel']})\")\n",
    "    if i < len(path_ids)-1:\n",
    "        print(\"   │\")\n",
    "        print(\"   ↓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d2d0e0",
   "metadata": {},
   "source": [
    "#### Exploration over single category of relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffce8b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Component-Whole examples: 941\n"
     ]
    }
   ],
   "source": [
    "comp_whole_examples = [\n",
    "    ex for ex in train_examples \n",
    "    if ex[\"relation\"].startswith(\"Component-Whole\")\n",
    "]\n",
    "\n",
    "print(\"Number of Component-Whole examples:\", len(comp_whole_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ef7dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "def get_sdp(example):\n",
    "    tokens = example[\"tokens\"]\n",
    "\n",
    "    # map id → head, id → token\n",
    "    graph = defaultdict(list)\n",
    "    for tok in tokens:\n",
    "        tid = int(tok[\"id\"])\n",
    "        head = int(tok[\"head\"])\n",
    "        if head != 0:\n",
    "            graph[tid].append(head)\n",
    "            graph[head].append(tid)\n",
    "\n",
    "    # find e1 and e2 token ids\n",
    "    e1_id, e2_id = None, None\n",
    "    for tok in tokens:\n",
    "        if tok[\"entity\"] == \"Entity=e1\":\n",
    "            e1_id = int(tok[\"id\"])\n",
    "        if tok[\"entity\"] == \"Entity=e2\":\n",
    "            e2_id = int(tok[\"id\"])\n",
    "\n",
    "    # BFS shortest path\n",
    "    queue = deque([(e1_id, [e1_id])])\n",
    "    visited = {e1_id}\n",
    "\n",
    "    while queue:\n",
    "        node, path = queue.popleft()\n",
    "        if node == e2_id:\n",
    "            return path\n",
    "        for nei in graph[node]:\n",
    "            if nei not in visited:\n",
    "                visited.add(nei)\n",
    "                queue.append((nei, path + [nei]))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00b2880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdp_pattern(example):\n",
    "    path = get_sdp(example)\n",
    "    tokens = example[\"tokens\"]\n",
    "\n",
    "    words = []\n",
    "    lemmas = []\n",
    "    pos = []\n",
    "    deps = []\n",
    "\n",
    "    for i in range(len(path)):\n",
    "        tid = path[i]\n",
    "        tok = tokens[tid - 1]\n",
    "\n",
    "        words.append(tok[\"form\"])\n",
    "        lemmas.append(tok[\"lemma\"])\n",
    "        pos.append(tok[\"upos\"])\n",
    "\n",
    "        # dependency relation between this node and next\n",
    "        if i < len(path) - 1:\n",
    "            t1 = tokens[path[i] - 1]\n",
    "            t2 = tokens[path[i+1] - 1]\n",
    "\n",
    "            # determine which token is the dependent\n",
    "            if int(t1[\"head\"]) == int(t2[\"id\"]):\n",
    "                deps.append(t1[\"deprel\"])  # t1 → head = t2\n",
    "            elif int(t2[\"head\"]) == int(t1[\"id\"]):\n",
    "                deps.append(t2[\"deprel\"])  # t2 → head = t1\n",
    "            else:\n",
    "                deps.append(\"unknown\")\n",
    "\n",
    "    return {\n",
    "        \"words\": tuple(words),\n",
    "        \"lemmas\": tuple(lemmas),\n",
    "        \"pos\": tuple(pos),\n",
    "        \"deps\": tuple(deps)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f5ac61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top lemma paths:\n",
      "4 → stem -- of -- tree\n",
      "3 → cover -- of -- magazine\n",
      "3 → knife -- blade\n",
      "3 → shelf -- of -- refrigerator\n",
      "3 → television -- screen\n",
      "2 → ear -- lobe\n",
      "2 → umbrella -- frame\n",
      "2 → rope -- of -- bell\n",
      "2 → flower -- bud\n",
      "2 → pin -- of -- connector\n",
      "2 → floor -- of -- cottage\n",
      "2 → mouse -- button\n",
      "2 → bristle -- of -- brush\n",
      "2 → fish -- with -- lung\n",
      "2 → jaw -- bone\n",
      "\n",
      "Top POS paths:\n",
      "345 → NOUN -- ADP -- NOUN\n",
      "161 → NOUN -- VERB -- NOUN\n",
      "120 → NOUN -- VERB -- ADP -- NOUN\n",
      "105 → NOUN -- NOUN\n",
      "32 → NOUN -- AUX -- NOUN -- ADP -- NOUN\n",
      "13 → NOUN -- VERB -- NOUN -- ADP -- NOUN\n",
      "11 → NOUN -- VERB -- VERB -- NOUN\n",
      "8 → NOUN -- ADP -- NOUN -- VERB -- NOUN\n",
      "8 → NOUN -- VERB -- NOUN -- NOUN\n",
      "7 → NOUN -- ADP -- PROPN\n",
      "\n",
      "Top dependency-label paths:\n",
      "354 → prep -- pobj\n",
      "147 → nsubj -- dobj\n",
      "88 → compound\n",
      "43 → nsubjpass -- prep -- pobj\n",
      "34 → nsubj -- prep -- pobj\n",
      "31 → nsubj -- attr -- prep -- pobj\n",
      "28 → dobj -- prep -- pobj\n",
      "16 → poss\n",
      "14 → acl -- prep -- pobj\n",
      "12 → nsubj -- dobj -- prep -- pobj\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "lemma_paths = Counter([p[\"lemmas\"] for p in patterns])\n",
    "pos_paths    = Counter([p[\"pos\"] for p in patterns])\n",
    "dep_paths    = Counter([p[\"deps\"] for p in patterns])\n",
    "\n",
    "print(\"Top lemma paths:\")\n",
    "for path, count in lemma_paths.most_common(15):\n",
    "    print(count, \"→\", \" -- \".join(path))\n",
    "\n",
    "print(\"\\nTop POS paths:\")\n",
    "for path, count in pos_paths.most_common(10):\n",
    "    print(count, \"→\", \" -- \".join(path))\n",
    "\n",
    "print(\"\\nTop dependency-label paths:\")\n",
    "for path, count in dep_paths.most_common(10):\n",
    "    print(count, \"→\", \" -- \".join(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff86a9e1",
   "metadata": {},
   "source": [
    "#### Usage of DepencenyMatcher on single category through single pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ed47f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import DependencyMatcher\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "matcher = DependencyMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23446eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_of_phrase = [\n",
    "    # The WHOLE token (head of \"of\")\n",
    "    {\n",
    "        \"RIGHT_ID\": \"whole\",\n",
    "        \"RIGHT_ATTRS\": {\"POS\": \"NOUN\"}\n",
    "    },\n",
    "    # The preposition \"of\"\n",
    "    {\n",
    "        \"LEFT_ID\": \"whole\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"prep_of\",\n",
    "        \"RIGHT_ATTRS\": {\"LOWER\": \"of\"}\n",
    "    },\n",
    "    # The COMPONENT token\n",
    "    {\n",
    "        \"LEFT_ID\": \"prep_of\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"component\",\n",
    "        \"RIGHT_ATTRS\": {\"POS\": \"NOUN\"}\n",
    "    }\n",
    "]\n",
    "matcher.add(\"COMP_WHOLE_OF_PHRASE\", [pattern_of_phrase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9dfbfcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_from_conllu(example):\n",
    "    words = [t[\"form\"] for t in example[\"tokens\"]]\n",
    "    spaces = [True] * len(words)\n",
    "    if len(spaces) > 0:\n",
    "        spaces[-1] = False # Last token usually doesn't have space if it's punctuation, but simple approx\n",
    "    \n",
    "    doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "    \n",
    "    for i, t in enumerate(example[\"tokens\"]):\n",
    "        # Set POS and dependency labels if needed, but DependencyMatcher works on Doc attributes\n",
    "        # We need to set them manually if we want to match on them\n",
    "        # Note: Spacy's DependencyMatcher requires a parsed Doc. \n",
    "        # Since we have CoNLL-U data, we can either:\n",
    "        # 1. Use the CoNLL-U tags/deps to set attributes on the Doc (requires custom extension or setting protected attrs)\n",
    "        # 2. Run nlp() on the text (might differ from CoNLL-U)\n",
    "        pass\n",
    "        \n",
    "    # For simplicity and to use the matcher effectively with the *exact* CoNLL-U structure,\n",
    "    # we should ideally construct the Doc with the CoNLL-U dependencies.\n",
    "    # However, setting heads/deps manually on a Doc is tricky.\n",
    "    # Let's try running nlp() on the text first as a quick start, \n",
    "    # or better, let's use the provided example text.\n",
    "    \n",
    "    text = example.get(\"text\", \" \".join(words))\n",
    "    return nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "988fbbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning 941 Component-Whole examples...\n",
      "\n",
      "Sentence: The system as described above has its greatest application in an arrayed configuration of antenna elements.\n",
      "Match: configuration -> of -> elements\n",
      "\n",
      "Sentence: The girl showed a photo of apple tree blossom on a fruit tree in the Central Valley.\n",
      "Match: photo -> of -> tree\n",
      "\n",
      "Sentence: The timer of the device automatically eliminates wasted \"standby power\" consumption by automatically turn off electronics plugged into the \"auto off\" outlets.\n",
      "Match: timer -> of -> device\n"
     ]
    }
   ],
   "source": [
    "# Filter examples for Component-Whole relations\n",
    "comp_whole_examples = [ex for ex in train_examples if \"Component-Whole\" in ex[\"relation\"]]\n",
    "\n",
    "# Apply matcher to a subset of examples\n",
    "print(f\"Scanning {len(comp_whole_examples)} Component-Whole examples...\")\n",
    "for ex in comp_whole_examples[:5]: # Test on first 5 examples\n",
    "    doc = doc_from_conllu(ex)\n",
    "    matches = matcher(doc)\n",
    "    if matches:\n",
    "        print(f\"\\nSentence: {ex['text']}\")\n",
    "        for match_id, token_ids in matches:\n",
    "            w_id, p_id, c_id = token_ids\n",
    "            print(f\"Match: {doc[w_id]} -> {doc[p_id]} -> {doc[c_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8299c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_matches(examples):\n",
    "    print(f\"\\nAnalyzing {len(examples)} Component-Whole examples...\")\n",
    "\n",
    "    for ex in examples:\n",
    "        doc = doc_from_conllu(ex)\n",
    "        matches = matcher(doc)\n",
    "\n",
    "        if not matches:\n",
    "            continue\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Sentence:\", ex[\"text\"])\n",
    "        print(f\"Gold e1: {ex['e1']['text']}   Gold e2: {ex['e2']['text']}\")\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        for match_id, token_ids in matches:\n",
    "            pattern = nlp.vocab.strings[match_id]\n",
    "\n",
    "            # dynamic length: compound patterns may only have 2 tokens\n",
    "            tokens = [doc[t] for t in token_ids]\n",
    "\n",
    "            # extract for readable formatting\n",
    "            words = [f\"{tok.text}/{tok.dep_}\" for tok in tokens]\n",
    "\n",
    "            # try to guess component vs whole\n",
    "            if len(tokens) == 3:\n",
    "                whole = tokens[0]\n",
    "                prep = tokens[1]\n",
    "                comp = tokens[2]\n",
    "            else:\n",
    "                # compound or poss patterns\n",
    "                whole = tokens[0]\n",
    "                comp = tokens[-1]\n",
    "\n",
    "            # Compare with gold labels\n",
    "            gold_e1 = ex[\"e1\"][\"text\"].lower()\n",
    "            gold_e2 = ex[\"e2\"][\"text\"].lower()\n",
    "\n",
    "            print(f\"Pattern: {pattern}\")\n",
    "            print(\"Tokens:\", \" -> \".join(words))\n",
    "            print(f\"Extracted component: {comp.text}, whole: {whole.text}\")\n",
    "            print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ad08098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing 20 Component-Whole examples...\n",
      "\n",
      "================================================================================\n",
      "Sentence: The system as described above has its greatest application in an arrayed configuration of antenna elements.\n",
      "Gold e1: configuration   Gold e2: elements\n",
      "--------------------------------------------------------------------------------\n",
      "Pattern: COMP_WHOLE_OF_PHRASE\n",
      "Tokens: configuration/pobj -> of/prep -> elements/pobj\n",
      "Extracted component: elements, whole: configuration\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Sentence: The girl showed a photo of apple tree blossom on a fruit tree in the Central Valley.\n",
      "Gold e1: tree   Gold e2: blossom\n",
      "--------------------------------------------------------------------------------\n",
      "Pattern: COMP_WHOLE_OF_PHRASE\n",
      "Tokens: photo/dobj -> of/prep -> tree/pobj\n",
      "Extracted component: tree, whole: photo\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Sentence: The timer of the device automatically eliminates wasted \"standby power\" consumption by automatically turn off electronics plugged into the \"auto off\" outlets.\n",
      "Gold e1: timer   Gold e2: device\n",
      "--------------------------------------------------------------------------------\n",
      "Pattern: COMP_WHOLE_OF_PHRASE\n",
      "Tokens: timer/nsubj -> of/prep -> device/pobj\n",
      "Extracted component: device, whole: timer\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Sentence: He decided to pad the heel of shoes with a shock absorbing insole or heel pad.\n",
      "Gold e1: heel   Gold e2: shoes\n",
      "--------------------------------------------------------------------------------\n",
      "Pattern: COMP_WHOLE_OF_PHRASE\n",
      "Tokens: heel/dobj -> of/prep -> shoes/pobj\n",
      "Extracted component: shoes, whole: heel\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Sentence: The picture below shows a view chapel and west range of the inner courtyard of the castle.\n",
      "Gold e1: courtyard   Gold e2: castle\n",
      "--------------------------------------------------------------------------------\n",
      "Pattern: COMP_WHOLE_OF_PHRASE\n",
      "Tokens: chapel/dobj -> of/prep -> courtyard/pobj\n",
      "Extracted component: courtyard, whole: chapel\n",
      "--------------------------------------------------------------------------------\n",
      "Pattern: COMP_WHOLE_OF_PHRASE\n",
      "Tokens: courtyard/pobj -> of/prep -> castle/pobj\n",
      "Extracted component: castle, whole: courtyard\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Sentence: The nose of a bloodhound is so good that evidence found by a bloodhound will hold up in matters involving the United States Supreme Court.\n",
      "Gold e1: nose   Gold e2: bloodhound\n",
      "--------------------------------------------------------------------------------\n",
      "Pattern: COMP_WHOLE_OF_PHRASE\n",
      "Tokens: nose/nsubj -> of/prep -> bloodhound/pobj\n",
      "Extracted component: bloodhound, whole: nose\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Sentence: He stopped rowing when the boat was opposite to the paddle wheel of the steamer, and the steamer stopped her engine at the same time.\n",
      "Gold e1: steamer   Gold e2: engine\n",
      "--------------------------------------------------------------------------------\n",
      "Pattern: COMP_WHOLE_OF_PHRASE\n",
      "Tokens: wheel/pobj -> of/prep -> steamer/pobj\n",
      "Extracted component: steamer, whole: wheel\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Sentence: Our experience extends to 15 years continued promotion of this archipelago of nine islands.\n",
      "Gold e1: archipelago   Gold e2: islands\n",
      "--------------------------------------------------------------------------------\n",
      "Pattern: COMP_WHOLE_OF_PHRASE\n",
      "Tokens: promotion/dobj -> of/prep -> archipelago/pobj\n",
      "Extracted component: archipelago, whole: promotion\n",
      "--------------------------------------------------------------------------------\n",
      "Pattern: COMP_WHOLE_OF_PHRASE\n",
      "Tokens: archipelago/pobj -> of/prep -> islands/pobj\n",
      "Extracted component: islands, whole: archipelago\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Sentence: Isolated fractures of the shaft of the ulna, without other fractures, often result when the forearm is raised to fend off a blow.\n",
      "Gold e1: shaft   Gold e2: ulna\n",
      "--------------------------------------------------------------------------------\n",
      "Pattern: COMP_WHOLE_OF_PHRASE\n",
      "Tokens: fractures/nsubj -> of/prep -> shaft/pobj\n",
      "Extracted component: shaft, whole: fractures\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Sentence: The nasal cavity of birds contains turbinates (Bang 1971), cartilaginous structures that are thought to have as one of their functions water recovery from air.\n",
      "Gold e1: nasal cavity   Gold e2: birds\n",
      "--------------------------------------------------------------------------------\n",
      "Pattern: COMP_WHOLE_OF_PHRASE\n",
      "Tokens: cavity/nsubj -> of/prep -> birds/pobj\n",
      "Extracted component: birds, whole: cavity\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Sentence: We leave the bail of the reel open and place your the rod in a double mounted set up as shown on the facing page.\n",
      "Gold e1: bail   Gold e2: reel\n",
      "--------------------------------------------------------------------------------\n",
      "Pattern: COMP_WHOLE_OF_PHRASE\n",
      "Tokens: bail/dobj -> of/prep -> reel/pobj\n",
      "Extracted component: reel, whole: bail\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "explore_matches(comp_whole_examples[:20])   # inspect first 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db994c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Component-Whole examples: 941\n",
      "Correct matches (via `of` phrase): 279\n",
      "Not captured by this pattern: 662\n",
      "Coverage %: 29.64930924548353\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "total = len(comp_whole_examples)\n",
    "\n",
    "for ex in comp_whole_examples:\n",
    "    doc = doc_from_conllu(ex)\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    gold_e1 = ex[\"e1\"][\"text\"].lower()\n",
    "    gold_e2 = ex[\"e2\"][\"text\"].lower()\n",
    "\n",
    "    found = False\n",
    "\n",
    "    for _, (w_id, p_id, c_id) in matches:\n",
    "        whole = doc[w_id].text.lower()\n",
    "        comp  = doc[c_id].text.lower()\n",
    "\n",
    "        if whole == gold_e1 and comp == gold_e2:\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "\n",
    "print(\"Total Component-Whole examples:\", total)\n",
    "print(\"Correct matches (via `of` phrase):\", correct)\n",
    "print(\"Not captured by this pattern:\", wrong)\n",
    "print(\"Coverage %:\", correct / total * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be3249c",
   "metadata": {},
   "source": [
    "#### Adding other patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd269ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole --has/contains/includes/consists--> component\n",
    "pattern_verb_has = [\n",
    "    # whole = subject of verb\n",
    "    {\"RIGHT_ID\": \"whole\", \"RIGHT_ATTRS\": {\"POS\": \"NOUN\"}},\n",
    "    {\"LEFT_ID\": \"whole\", \"REL_OP\": \">\", \"RIGHT_ID\": \"verb\",\n",
    "     \"RIGHT_ATTRS\": {\"LEMMA\": {\"IN\": [\"have\", \"contain\", \"include\", \"consist\"]}}},\n",
    "    # component = object of verb or object of prep after verb\n",
    "    {\"LEFT_ID\": \"verb\", \"REL_OP\": \">\", \"RIGHT_ID\": \"component\",\n",
    "     \"RIGHT_ATTRS\": {\"POS\": \"NOUN\", \"DEP\": {\"IN\": [\"dobj\", \"pobj\"]}}}\n",
    "]\n",
    "\n",
    "matcher.add(\"COMP_WHOLE_VERB_HAS\", [pattern_verb_has])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c005ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_compound = [\n",
    "    # component is modifier (left noun)\n",
    "    {\"RIGHT_ID\": \"component\", \"RIGHT_ATTRS\": {\"POS\": \"NOUN\", \"DEP\": \"compound\"}},\n",
    "    # whole is its head noun\n",
    "    {\"LEFT_ID\": \"component\", \"REL_OP\": \">\", \"RIGHT_ID\": \"whole\",\n",
    "     \"RIGHT_ATTRS\": {\"POS\": \"NOUN\"}}\n",
    "]\n",
    "\n",
    "matcher.add(\"COMP_WHOLE_COMPOUND\", [pattern_compound])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd09e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_with = [\n",
    "    # whole noun\n",
    "    {\"RIGHT_ID\": \"whole\", \"RIGHT_ATTRS\": {\"POS\": \"NOUN\"}},\n",
    "    # prep = with\n",
    "    {\"LEFT_ID\": \"whole\", \"REL_OP\": \">\", \"RIGHT_ID\": \"prep_with\",\n",
    "     \"RIGHT_ATTRS\": {\"LOWER\": \"with\"}},\n",
    "    # component noun\n",
    "    {\"LEFT_ID\": \"prep_with\", \"REL_OP\": \">\", \"RIGHT_ID\": \"component\",\n",
    "     \"RIGHT_ATTRS\": {\"POS\": \"NOUN\"}}\n",
    "]\n",
    "\n",
    "matcher.add(\"COMP_WHOLE_WITH_PHRASE\", [pattern_with])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e50aca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_possessive = [\n",
    "    # whole is possessor\n",
    "    {\"RIGHT_ID\": \"whole\", \"RIGHT_ATTRS\": {\"POS\": \"NOUN\"}},\n",
    "    # possessive edge\n",
    "    {\"LEFT_ID\": \"whole\", \"REL_OP\": \">\", \"RIGHT_ID\": \"poss_marker\",\n",
    "     \"RIGHT_ATTRS\": {\"DEP\": \"poss\"}},\n",
    "    # component is head noun\n",
    "    {\"LEFT_ID\": \"poss_marker\", \"REL_OP\": \">\", \"RIGHT_ID\": \"component\",\n",
    "     \"RIGHT_ATTRS\": {\"POS\": \"NOUN\"}}\n",
    "]\n",
    "\n",
    "matcher.add(\"COMP_WHOLE_POSSESSIVE\", [pattern_possessive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "954c8dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e66f05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 941 Component-Whole examples...\n",
      "\n",
      "========== OVERALL COVERAGE ==========\n",
      "Total examples: 941\n",
      "Correctly captured: 302\n",
      "Missed: 639\n",
      "Coverage %: 32.09\n",
      "\n",
      "========== PER-PATTERN COVERAGE ==========\n",
      "COMP_WHOLE_OF_PHRASE:\n",
      "  correct: 280\n",
      "  wrong:   418\n",
      "  accuracy: 40.11%\n",
      "\n",
      "COMP_WHOLE_WITH_PHRASE:\n",
      "  correct: 16\n",
      "  wrong:   42\n",
      "  accuracy: 27.59%\n",
      "\n",
      "COMP_WHOLE_COMPOUND:\n",
      "  correct: 4\n",
      "  wrong:   57\n",
      "  accuracy: 6.56%\n",
      "\n",
      "COMP_WHOLE_VERB_HAS:\n",
      "  correct: 3\n",
      "  wrong:   17\n",
      "  accuracy: 15.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Track per-pattern statistics\n",
    "pattern_correct = defaultdict(int)\n",
    "pattern_wrong = defaultdict(int)\n",
    "\n",
    "overall_correct = 0\n",
    "overall_wrong = 0\n",
    "total = len(comp_whole_examples)\n",
    "\n",
    "\n",
    "def extract_whole_component(doc, token_ids):\n",
    "    \"\"\"\n",
    "    General extractor for any pattern:\n",
    "    - Find 2 nouns in the match\n",
    "    - The earlier one in the dependency direction is WHOLE\n",
    "    - The later one is COMPONENT\n",
    "\n",
    "    Works for:\n",
    "    - NOUN -> of -> NOUN\n",
    "    - NOUN -> with -> NOUN\n",
    "    - compound\n",
    "    - possessive\n",
    "    - verb-mediated (whole--verb-->component)\n",
    "    \"\"\"\n",
    "    nouns = [i for i in token_ids if doc[i].pos_ == \"NOUN\"]\n",
    "    if len(nouns) < 2:\n",
    "        return None, None\n",
    "    \n",
    "    # Sort tokens by index to get deterministic ordering\n",
    "    nouns = sorted(nouns)\n",
    "\n",
    "    whole = doc[nouns[0]].text.lower()\n",
    "    component = doc[nouns[-1]].text.lower()\n",
    "    \n",
    "    return whole, component\n",
    "\n",
    "\n",
    "print(f\"Evaluating {total} Component-Whole examples...\\n\")\n",
    "\n",
    "for ex in comp_whole_examples:\n",
    "    doc = doc_from_conllu(ex)\n",
    "    gold_e1 = ex[\"e1\"][\"text\"].lower()\n",
    "    gold_e2 = ex[\"e2\"][\"text\"].lower()\n",
    "\n",
    "    matches = matcher(doc)\n",
    "    found_match_for_sentence = False\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        rule_name = nlp.vocab.strings[match_id]\n",
    "\n",
    "        whole, comp = extract_whole_component(doc, token_ids)\n",
    "        if whole is None:\n",
    "            continue\n",
    "\n",
    "        if whole == gold_e1 and comp == gold_e2:\n",
    "            pattern_correct[rule_name] += 1\n",
    "            found_match_for_sentence = True\n",
    "        else:\n",
    "            pattern_wrong[rule_name] += 1\n",
    "\n",
    "    if found_match_for_sentence:\n",
    "        overall_correct += 1\n",
    "    else:\n",
    "        overall_wrong += 1\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# PRINT RESULTS\n",
    "# ---------------------------\n",
    "print(\"========== OVERALL COVERAGE ==========\")\n",
    "print(\"Total examples:\", total)\n",
    "print(\"Correctly captured:\", overall_correct)\n",
    "print(\"Missed:\", overall_wrong)\n",
    "print(\"Coverage %:\", round(overall_correct / total * 100, 2))\n",
    "print()\n",
    "\n",
    "print(\"========== PER-PATTERN COVERAGE ==========\")\n",
    "for pattern_name in pattern_correct:\n",
    "    total_matches = pattern_correct[pattern_name] + pattern_wrong[pattern_name]\n",
    "    accuracy = pattern_correct[pattern_name] / total_matches * 100 if total_matches > 0 else 0\n",
    "\n",
    "    print(f\"{pattern_name}:\")\n",
    "    print(f\"  correct: {pattern_correct[pattern_name]}\")\n",
    "    print(f\"  wrong:   {pattern_wrong[pattern_name]}\")\n",
    "    print(f\"  accuracy: {accuracy:.2f}%\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
