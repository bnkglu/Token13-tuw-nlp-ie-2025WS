{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f469f9e2",
   "metadata": {},
   "source": [
    "# Explainable Rule-Based Relation Extraction\n",
    "## Milestone 2 - SemEval 2010 Task 8\n",
    "\n",
    "**Objective:** Implement and evaluate a deterministic, rule-based system for relation extraction that is both effective and fully explainable.\n",
    "\n",
    "This notebook details the process of building a relation extraction system using spaCy. The core of this approach is an automatic rule discovery mechanism that mines patterns from training data, filters them based on statistical quality (precision and support), and applies them using spaCy's efficient matchers.\n",
    "\n",
    "**Key Goals for Milestone 2:**\n",
    "1.  **Implement a Baseline:** Develop a rule-based system from scratch.\n",
    "2.  **Quantitative Evaluation:** Measure performance using metrics like accuracy, precision, recall, and F1-score.\n",
    "3.  **Qualitative Analysis:** Analyze the system's behavior, understand its strengths through explainability, and investigate its weaknesses through error analysis.\n",
    "\n",
    "This notebook will walk through each of these steps, from data preparation to the final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b98999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/berke/Desktop/School/TU_Wien-MSC/2025W/194.093_NLP-IE/Project/Token13-tuw-nlp-ie-2025WS/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n",
      "spaCy version: 3.8.11\n",
      "Current working directory: /Users/berke/Desktop/School/TU_Wien-MSC/2025W/194.093_NLP-IE/Project/Token13-tuw-nlp-ie-2025WS\n",
      "\n",
      "Loading datasets...\n",
      "Training samples: 8000\n",
      "Test samples: 2717\n",
      "Training samples: 8000\n",
      "Test samples: 2717\n"
     ]
    }
   ],
   "source": [
    "## 1. Setup: Libraries and Data Loading\n",
    "\n",
    "# === 1.1 Import Libraries ===\n",
    "import json\n",
    "import numpy as np\n",
    "import spacy\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# === 1.2 Load spaCy Model ===\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(f\"spaCy version: {spacy.__version__}\")\n",
    "\n",
    "# === 1.3 Load Datasets ===\n",
    "# Set working directory to the project root for consistent paths\n",
    "# Assumes the notebook is run from the root of the project\n",
    "print(f\"Current working directory: {Path.cwd()}\")\n",
    "\n",
    "print(\"\\nLoading datasets...\")\n",
    "try:\n",
    "    with open('../data/processed/train/train.json', 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "\n",
    "    with open('../data/processed/test/test.json', 'r') as f:\n",
    "        test_data = json.load(f)\n",
    "\n",
    "    print(f\"Training samples: {len(train_data)}\")\n",
    "    print(f\"Test samples: {len(test_data)}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Make sure you have run the preprocessing scripts and that the data files exist at the specified paths.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c29b9",
   "metadata": {},
   "source": [
    "## 2. Data Processing and Feature Extraction\n",
    "\n",
    "To build reliable rule-based patterns, we first transform each annotated sample into a structured linguistic representation. This preprocessing stage provides all the features our rule induction and matching steps depend on.\n",
    "\n",
    "1. **Reconstructing spaCy `Doc` Objects**\n",
    "\n",
    "    We rebuild spaCy `Doc` objects directly from the pre-tokenized JSON annotations.\n",
    "    This gives us access to tokens, lemmas, POS tags, and dependency heads **without** running the spaCy NLP pipeline again.\n",
    "    Each `Doc` is therefore lightweight but still fully compatible with spaCy’s token and dependency operations.\n",
    "\n",
    "2. **Identifying Entity Spans**\n",
    "\n",
    "    For each sample, we use the token indices of the annotated entities (`e1` and `e2`) to recover their corresponding `Span` objects inside the reconstructed `Doc`.\n",
    "    These spans give us the entity roots, their heads, and their token ranges.\n",
    "\n",
    "3. **Extracting Linguistic Features**\n",
    "\n",
    "    We compute two core features for rule construction:\n",
    "\n",
    "    * **Dependency Path**:\n",
    "    Instead of using spaCy’s LCA matrix, we compute the dependency path between the entity roots by traversing their ancestor chains and locating the first common ancestor manually.\n",
    "    This method is simple, deterministic, and works cleanly with our reconstructed dependency trees.\n",
    "\n",
    "    * **Between-Entity Tokens**:\n",
    "    We extract the exact token span between `e1` and `e2`, capturing intermediate lemmas, POS tags, and dependency labels.\n",
    "    These between-words often encode strong relational cues (e.g., “caused by”, “part of”, “located in”).\n",
    "        - **Span**: the continuous sequence of tokens lying strictly between the two entity spans.\n",
    "            *Example*: In “A binds to B”, the span between `e1 = A` and `e2 = B` is the tokens “binds to”.\n",
    "\n",
    "Together, these features give a compact but expressive description of how the two entities relate within the sentence.\n",
    "\n",
    "The following functions implement this preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c9558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "\n",
    "def doc_from_json(item, nlp):\n",
    "    \"\"\"\n",
    "    Create a spaCy Doc from pre-computed JSON annotations.\n",
    "    \"\"\"\n",
    "    tokens_data = item['tokens']\n",
    "    \n",
    "    # Extract token attributes\n",
    "    words = [t['text'] for t in tokens_data]\n",
    "    spaces = [i < len(words) - 1 for i in range(len(words))]\n",
    "    \n",
    "    # Create Doc with words and spaces\n",
    "    doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "    \n",
    "    # Set linguistic attributes from pre-computed data\n",
    "    for token, token_data in zip(doc, tokens_data):\n",
    "        token.lemma_ = token_data['lemma']\n",
    "        token.pos_ = token_data['pos']\n",
    "        token.tag_ = token_data['tag']\n",
    "        token.dep_ = token_data['dep']\n",
    "        \n",
    "        # Set head (dependency parent)\n",
    "        head_id = token_data['head']\n",
    "        if head_id != token.i:\n",
    "            token.head = doc[head_id]\n",
    "    \n",
    "    return doc\n",
    "\n",
    "\n",
    "def get_dependency_path(doc, e1_span, e2_span):\n",
    "    \"\"\"Extract dependency path between entity roots via LCA (no matrix).\"\"\"\n",
    "    e1_root = e1_span.root\n",
    "    e2_root = e2_span.root\n",
    "    \n",
    "    # Collect ancestors from e1_root to the root\n",
    "    ancestors_e1 = []\n",
    "    cur = e1_root\n",
    "    while True:\n",
    "        ancestors_e1.append(cur)\n",
    "        if cur.head == cur:  # reached root\n",
    "            break\n",
    "        cur = cur.head\n",
    "    \n",
    "    # Walk up from e2_root until we hit something in ancestors_e1\n",
    "    path_down_nodes = []\n",
    "    cur = e2_root\n",
    "    while cur not in ancestors_e1:\n",
    "        path_down_nodes.append(cur)\n",
    "        if cur.head == cur:  # fallback, no intersection (shouldn't happen in a tree)\n",
    "            break\n",
    "        cur = cur.head\n",
    "    \n",
    "    lca = cur\n",
    "    # nodes from e1_root up to LCA (exclusive)\n",
    "    path_up_nodes = []\n",
    "    cur = e1_root\n",
    "    while cur != lca:\n",
    "        path_up_nodes.append(cur)\n",
    "        cur = cur.head\n",
    "    \n",
    "    # Build features\n",
    "    path_up = [(t.dep_, t.pos_, t.lemma_) for t in path_up_nodes]\n",
    "    lca_feat = (lca.dep_, lca.pos_, lca.lemma_)\n",
    "    path_down = [(t.dep_, t.pos_, t.lemma_) for t in reversed(path_down_nodes)]\n",
    "\n",
    "    return path_up + [lca_feat] + path_down\n",
    "\n",
    "\n",
    "def get_between_span(doc, e1_span, e2_span):\n",
    "    \"\"\"Get span between entities using Doc slicing.\"\"\"\n",
    "    if e1_span.start < e2_span.start:\n",
    "        return doc[e1_span.end:e2_span.start]\n",
    "    return doc[e2_span.end:e1_span.start]\n",
    "\n",
    "\n",
    "def preprocess_data(data_list, nlp):\n",
    "    \"\"\"\n",
    "    Process data using pre-computed annotations from JSON.\n",
    "    \"\"\"\n",
    "    processed = []\n",
    "    \n",
    "    for item in tqdm(data_list, desc=\"Processing\"):\n",
    "        # Create Doc from pre-computed annotations\n",
    "        doc = doc_from_json(item, nlp)\n",
    "        \n",
    "        e1_info = item['entities'][0]\n",
    "        e2_info = item['entities'][1]\n",
    "        \n",
    "        # Create spans using token indices\n",
    "        e1_token_ids = e1_info['token_ids']\n",
    "        e2_token_ids = e2_info['token_ids']\n",
    "        e1_span = doc[min(e1_token_ids):max(e1_token_ids)+1]\n",
    "        e2_span = doc[min(e2_token_ids):max(e2_token_ids)+1]\n",
    "        \n",
    "        # Extract features\n",
    "        dep_path = get_dependency_path(doc, e1_span, e2_span)\n",
    "        between_span = get_between_span(doc, e1_span, e2_span)\n",
    "        \n",
    "        between_words = [\n",
    "            {'text': t.text, 'lemma': t.lemma_, 'pos': t.pos_, 'dep': t.dep_}\n",
    "            for t in between_span\n",
    "        ]\n",
    "        \n",
    "        processed.append({\n",
    "            'id': item['id'],\n",
    "            'text': item['text'],\n",
    "            'doc': doc,\n",
    "            'e1_span': e1_span,\n",
    "            'e2_span': e2_span,\n",
    "            'relation': item['relation']['type'],\n",
    "            'direction': item['relation'].get('direction', ''),\n",
    "            'dep_path': dep_path,\n",
    "            'between_words': between_words\n",
    "        })\n",
    "    \n",
    "    return processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dad62d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 8000/8000 [00:00<00:00, 9440.13it/s] \n",
      "Processing: 100%|██████████| 8000/8000 [00:00<00:00, 9440.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 2717/2717 [00:00<00:00, 13037.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 8000 training samples\n",
      "Processed 2717 test samples\n",
      "\n",
      "================================================================================\n",
      "Sample output:\n",
      "================================================================================\n",
      "Text: The system as described above has its greatest application in an arrayed configuration of antenna elements.\n",
      "Entity 1: configuration (POS: NOUN, DEP: pobj)\n",
      "Entity 2: elements (POS: NOUN, DEP: pobj)\n",
      "Relation: Component-Whole\n",
      "\n",
      "Dependency path: [('pobj', 'NOUN', 'configuration'), ('prep', 'ADP', 'of'), ('pobj', 'NOUN', 'element')]...\n",
      "Between words: ['of', 'antenna']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process train and test data\n",
    "print(\"Processing data...\")\n",
    "print()\n",
    "\n",
    "train_processed = preprocess_data(train_data, nlp)\n",
    "print(\"\\nProcessing test data...\")\n",
    "test_processed = preprocess_data(test_data, nlp)\n",
    "\n",
    "print(f\"\\nProcessed {len(train_processed)} training samples\")\n",
    "print(f\"Processed {len(test_processed)} test samples\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample output:\")\n",
    "print(\"=\"*80)\n",
    "sample = train_processed[0]\n",
    "doc = sample['doc']\n",
    "e1_span = sample['e1_span']\n",
    "e2_span = sample['e2_span']\n",
    "\n",
    "print(f\"Text: {sample['text']}\")\n",
    "print(f\"Entity 1: {e1_span.text} (POS: {e1_span.root.pos_}, DEP: {e1_span.root.dep_})\")\n",
    "print(f\"Entity 2: {e2_span.text} (POS: {e2_span.root.pos_}, DEP: {e2_span.root.dep_})\")\n",
    "print(f\"Relation: {sample['relation']}\")\n",
    "print(f\"\\nDependency path: {sample['dep_path'][:3]}...\")\n",
    "print(f\"Between words: {[w['text'] for w in sample['between_words']]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81716341",
   "metadata": {},
   "source": [
    "## 3.5 Exploratory Data Analysis - Extract Patterns from Data\n",
    "\n",
    "Before defining rules manually, let's analyze the actual dataset to discover:\n",
    "1. Most frequent words/lemmas per relation type\n",
    "2. Common verbs and prepositions for each relation\n",
    "3. Dependency patterns extracted from the shortest path between entity roots\n",
    "4. Discriminative features that distinguish relations\n",
    "\n",
    "---\n",
    "\n",
    "**Why These Default Values?**\n",
    "\n",
    "**Keywords: 30** — Open-class words (nouns, adjectives) have high variety; need more examples to capture diverse expressions  \n",
    "**Verbs: 15** — Medium-sized vocabulary; syntactic backbone of relations  \n",
    "**Prepositions: 10** — Small closed-class set (~70 in English); highly discriminative\n",
    "\n",
    "These balance **coverage** (capture enough patterns) vs. **precision** (avoid noise).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb50780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patterns_from_analysis(relation_features, top_n_keywords=30, top_n_verbs=15, top_n_preps=10):\n",
    "    \"\"\"\n",
    "    Generate RELATION_PATTERNS dictionary from data analysis.\n",
    "    Extract most frequent and distinctive features per relation.\n",
    "    \"\"\"\n",
    "    generated_patterns = {}\n",
    "    \n",
    "    for relation, features in relation_features.items():\n",
    "        # Extract top keywords (lemmas)\n",
    "        keywords = [lemma for lemma, count in features['top_lemmas'][:top_n_keywords]]\n",
    "        \n",
    "        # Extract top verbs\n",
    "        verbs = [verb for verb, count in features['top_verbs'][:top_n_verbs]]\n",
    "        \n",
    "        # Extract top prepositions\n",
    "        preps = [prep for prep, count in features['top_preps'][:top_n_preps]]\n",
    "        \n",
    "        # Extract dependency patterns (convert tuples back to lists)\n",
    "        dep_patterns = []\n",
    "        for path, count in features['top_dep_paths'][:5]:\n",
    "            if len(path) >= 2:  # At least 2 dependencies\n",
    "                dep_patterns.append(list(path[:3]))  # Take first 3 deps\n",
    "        \n",
    "        generated_patterns[relation] = {\n",
    "            'keywords': keywords,\n",
    "            'prep_patterns': preps,\n",
    "            'verb_patterns': verbs,\n",
    "            'dependency_patterns': dep_patterns\n",
    "        }\n",
    "    \n",
    "    return generated_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bece4238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_relation_features(processed_data):\n",
    "    \"\"\"\n",
    "    Analyze linguistic features for each relation type.\n",
    "    Returns dictionaries of feature frequencies per relation.\n",
    "    \"\"\"\n",
    "    # Group by relation type\n",
    "    relation_groups = defaultdict(list)\n",
    "    for sample in processed_data:\n",
    "        relation_groups[sample['relation']].append(sample)\n",
    "    \n",
    "    # Analyze each relation\n",
    "    relation_analysis = {}\n",
    "    \n",
    "    for relation, samples in relation_groups.items():\n",
    "        # Collect features from all samples of this relation\n",
    "        all_lemmas = []\n",
    "        all_verbs = []\n",
    "        all_preps = []\n",
    "        all_dep_paths = []\n",
    "        all_between_words = []\n",
    "        \n",
    "        for sample in samples:\n",
    "            doc = sample['doc']\n",
    "            \n",
    "            # Collect lemmas (excluding entities)\n",
    "            e1_tokens = set(range(sample['e1_span'].start, sample['e1_span'].end))\n",
    "            e2_tokens = set(range(sample['e2_span'].start, sample['e2_span'].end))\n",
    "            \n",
    "            for token in doc:\n",
    "                if token.i not in e1_tokens and token.i not in e2_tokens:\n",
    "                    lemma = token.lemma_.lower()\n",
    "                    \n",
    "                    # Collect verbs (don't filter stopwords for verbs)\n",
    "                    if token.pos_ == 'VERB' and not token.is_punct and len(lemma) > 2:\n",
    "                        all_verbs.append(lemma)\n",
    "                    \n",
    "                    # Collect prepositions (INCLUDE stopwords like \"of\", \"in\", \"at\")\n",
    "                    if token.pos_ == 'ADP' and not token.is_punct:\n",
    "                        all_preps.append(lemma)\n",
    "                    \n",
    "                    # Collect other lemmas (filter stopwords for general keywords)\n",
    "                    if not token.is_stop and not token.is_punct and len(lemma) > 2:\n",
    "                        all_lemmas.append(lemma)\n",
    "            \n",
    "            # Collect dependency paths (sequence of dependency labels along shortest path)\n",
    "            if sample['dep_path']:\n",
    "                path_deps = tuple([d[0] for d in sample['dep_path']])\n",
    "                all_dep_paths.append(path_deps)\n",
    "            \n",
    "            # Between words (fixed: should be \"if word['text'].strip()\" not \"if not\")\n",
    "            for word in sample['between_words']:\n",
    "                if word['text'].strip() and len(word['lemma']) > 2:\n",
    "                    all_between_words.append(word['lemma'].lower())\n",
    "        \n",
    "        # Count frequencies\n",
    "        lemma_freq = Counter(all_lemmas).most_common(30)\n",
    "        verb_freq = Counter(all_verbs).most_common(15)\n",
    "        prep_freq = Counter(all_preps).most_common(10)\n",
    "        dep_path_freq = Counter(all_dep_paths).most_common(10)\n",
    "        between_freq = Counter(all_between_words).most_common(20)\n",
    "        \n",
    "        relation_analysis[relation] = {\n",
    "            'count': len(samples),\n",
    "            'top_lemmas': lemma_freq,\n",
    "            'top_verbs': verb_freq,\n",
    "            'top_preps': prep_freq,\n",
    "            'top_dep_paths': dep_path_freq,\n",
    "            'top_between_words': between_freq\n",
    "        }\n",
    "    \n",
    "    return relation_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b64371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATING DATA-DRIVEN PATTERNS\n",
      "Top features per relation extracted from analysis\n",
      "================================================================================\n",
      "\n",
      "Cause-Effect:\n",
      "  Keywords (30): ['cause', 'result', 'lead', 'produce', 'trigger', 'year', 'come', 'people', 'water', 'time']\n",
      "  Verbs (15): ['cause', 'result', 'make', 'have', 'produce', 'trigger', 'come', 'lead', 'take', 'generate', 'use', 'get', 'find', 'help', 'follow']\n",
      "  Preps (10): ['of', 'by', 'in', 'from', 'to', 'on', 'with', 'for', 'as', 'at']\n",
      "  Dep patterns: 5 patterns extracted\n",
      "\n",
      "Component-Whole:\n",
      "  Keywords (30): ['comprise', 'contain', 'include', 'inside', 'hand', 'small', 'large', 'like', 'show', 'open']\n",
      "  Verbs (15): ['have', 'use', 'make', 'contain', 'comprise', 'include', 'show', 'see', 'consist', 'take', 'hold', 'provide', 'connect', 'compose', 'move']\n",
      "  Preps (10): ['of', 'in', 'with', 'on', 'to', 'for', 'from', 'at', 'by', 'as']\n",
      "  Dep patterns: 5 patterns extracted\n",
      "\n",
      "Content-Container:\n",
      "  Keywords (30): ['inside', 'contain', 'find', 'store', 'enclose', 'small', 'lock', 'plastic', 'hide', 'place']\n",
      "  Verbs (15): ['contain', 'find', 'store', 'enclose', 'have', 'lock', 'keep', 'hide', 'put', 'discover', 'use', 'make', 'place', 'carry', 'see']\n",
      "  Preps (10): ['in', 'of', 'with', 'inside', 'to', 'on', 'for', 'at', 'from', 'by']\n",
      "  Dep patterns: 5 patterns extracted\n",
      "\n",
      "Entity-Destination:\n",
      "  Keywords (30): ['place', 'pour', 'move', 'new', 'send', 'inside', 'release', 'migrate', 'drop', 'add']\n",
      "  Verbs (15): ['put', 'place', 'pour', 'move', 'send', 'release', 'migrate', 'add', 'drop', 'deliver', 'arrive', 'insert', 'spread', 'take', 'throw']\n",
      "  Preps (10): ['into', 'to', 'in', 'of', 'for', 'on', 'with', 'by', 'inside', 'from']\n",
      "  Dep patterns: 5 patterns extracted\n",
      "\n",
      "Entity-Origin:\n",
      "  Keywords (30): ['away', 'come', 'leave', 'derive', 'run', 'arrive', 'distil', 'originate', 'like', 'time']\n",
      "  Verbs (15): ['make', 'come', 'have', 'leave', 'use', 'derive', 'run', 'distil', 'arrive', 'originate', 'take', 'get', 'produce', 'find', 'fall']\n",
      "  Preps (10): ['from', 'of', 'in', 'to', 'with', 'for', 'on', 'by', 'out', 'as']\n",
      "  Dep patterns: 5 patterns extracted\n",
      "\n",
      "Instrument-Agency:\n",
      "  Keywords (30): ['use', 'order', 'apply', 'take', 'good', 'time', 'hand', 'help', 'work', 'create']\n",
      "  Verbs (15): ['use', 'take', 'apply', 'make', 'have', 'create', 'kill', 'show', 'attach', 'wield', 'find', 'work', 'hold', 'build', 'drive']\n",
      "  Preps (10): ['of', 'with', 'in', 'to', 'by', 'for', 'on', 'from', 'at', 'as']\n",
      "  Dep patterns: 5 patterns extracted\n",
      "\n",
      "Member-Collection:\n",
      "  Keywords (30): ['large', 'new', 'like', 'small', 'year', 'great', 'work', 'take', 'way', 'day']\n",
      "  Verbs (15): ['have', 'take', 'make', 'see', 'find', 'include', 'come', 'look', 'live', 'consist', 'work', 'become', 'use', 'bring', 'play']\n",
      "  Preps (10): ['of', 'in', 'to', 'with', 'on', 'for', 'from', 'by', 'as', 'at']\n",
      "  Dep patterns: 5 patterns extracted\n",
      "\n",
      "Message-Topic:\n",
      "  Keywords (30): ['new', 'describe', 'topic', 'subject', 'present', 'relate', 'discuss', 'give', 'reflect', 'set']\n",
      "  Verbs (15): ['make', 'give', 'describe', 'relate', 'discuss', 'have', 'reflect', 'explain', 'concern', 'present', 'provide', 'define', 'use', 'contain', 'point']\n",
      "  Preps (10): ['of', 'in', 'to', 'on', 'with', 'for', 'about', 'by', 'from', 'as']\n",
      "  Dep patterns: 5 patterns extracted\n",
      "\n",
      "Other:\n",
      "  Keywords (30): ['year', 'new', 'inside', 'time', 'make', 'start', 'work', 'take', 'come', 'great']\n",
      "  Verbs (15): ['make', 'use', 'have', 'take', 'start', 'come', 'see', 'keep', 'give', 'show', 'produce', 'contain', 'run', 'find', 'work']\n",
      "  Preps (10): ['of', 'in', 'with', 'to', 'from', 'for', 'into', 'by', 'on', 'at']\n",
      "  Dep patterns: 5 patterns extracted\n",
      "\n",
      "Product-Producer:\n",
      "  Keywords (30): ['produce', 'create', 'year', 'write', 'new', 'build', 'come', 'make', 'work', 'book']\n",
      "  Verbs (15): ['make', 'produce', 'create', 'write', 'build', 'come', 'use', 'complete', 'know', 'put', 'develop', 'work', 'construct', 'dig', 'take']\n",
      "  Preps (10): ['of', 'in', 'by', 'for', 'from', 'to', 'on', 'with', 'as', 'up']\n",
      "  Dep patterns: 5 patterns extracted\n",
      "\n",
      "================================================================================\n",
      "Data-driven patterns generated successfully!\n",
      "These patterns are based on actual frequency analysis of the training data.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate data-driven patterns\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING DATA-DRIVEN PATTERNS\")\n",
    "print(\"Top features per relation extracted from analysis\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# First, analyze the training data to get relation features\n",
    "relation_features = analyze_relation_features(train_processed)\n",
    "data_driven_patterns = generate_patterns_from_analysis(relation_features)\n",
    "\n",
    "# Display generated patterns\n",
    "for relation in sorted(data_driven_patterns.keys()):\n",
    "    patterns = data_driven_patterns[relation]\n",
    "    print(f\"\\n{relation}:\")\n",
    "    print(f\"  Keywords ({len(patterns['keywords'])}): {patterns['keywords'][:10]}\")\n",
    "    print(f\"  Verbs ({len(patterns['verb_patterns'])}): {patterns['verb_patterns']}\")\n",
    "    print(f\"  Preps ({len(patterns['prep_patterns'])}): {patterns['prep_patterns']}\")\n",
    "    print(f\"  Dep patterns: {len(patterns['dependency_patterns'])} patterns extracted\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Data-driven patterns generated successfully!\")\n",
    "print(\"These patterns are based on actual frequency analysis of the training data.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0538d7",
   "metadata": {},
   "source": [
    "## 4. Automatic Rule Discovery from Training Data\n",
    "\n",
    "We build a deterministic and fully explainable rule-based system by mining\n",
    "patterns from the training data and converting them into spaCy matchers\n",
    "(Matcher, PhraseMatcher, DependencyMatcher). Each discovered rule is associated\n",
    "with:\n",
    "\n",
    "- a predicted relation,\n",
    "- a precision value,\n",
    "- a support count, (the count for the relation with the highest frequency for that pattern)\n",
    "- and a human-readable explanation.\n",
    "\n",
    "All rules are ranked by (precision, support) and applied in a deterministic\n",
    "decision list: the highest-precision rule that matches is selected (\"first match\n",
    "wins\"). This produces an efficient, interpretable, and data-driven rule-based\n",
    "classifier.\n",
    "\n",
    "\n",
    "**Explainability** <br>\n",
    "A helper function plots top rules per relation, showing:\n",
    "   - pattern type,\n",
    "   - precision,\n",
    "   - support,\n",
    "   - and a short textual explanation.\n",
    "\n",
    "---\n",
    "\n",
    "## How Patterns Are Scored and Converted into Rules\n",
    "\n",
    "### 1. Pattern Mining\n",
    "\n",
    "For each training sentence we extract:\n",
    "\n",
    "- **Lexical patterns**\n",
    "   - `LEMMA`: single lemmas between the two entities  \n",
    "   - `BIGRAM`: lemma pairs between entities  \n",
    "   - `PREP`: prepositions (ADP) between entities  \n",
    "   - `BEFORE_E1` / `AFTER_E2`: context tokens next to entities  \n",
    "   - `ENTITY_POS`: `(POS(E1), POS(E2))` pair  \n",
    "\n",
    "- **Dependency patterns**\n",
    "   - `DEP_VERB`: verb lemma + dependency roles of both entities relative to that verb  \n",
    "   (e.g., `nsubj` → `contain` → `dobj` → Content-Container)\n",
    "   - `DEP_LABELS`: dependency labels of the entity heads\n",
    "\n",
    "For each pattern we store a frequency table:\n",
    "  - pattern_counts[pattern][relation] = number of occurrences\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Precision and Support Calculation\n",
    "\n",
    "In the `filter_and_rank_patterns` function, the precision for each rule is calculated as follows:\n",
    "\n",
    "1.  **`total_count`**: The total number of occurrences of a specific pattern across *all* relation types is summed up. \n",
    "   - $\\text{total} = \\sum_{\\text{relations}} \\text{count(pattern, relation)}$\n",
    "2.  **`best_count`**: The maximum count of this pattern for any single relation is identified. This represents the 'support' for the pattern's most frequent relation.\n",
    "   - $\\text{best\\_relation} = \\arg\\max_{\\text{r}} \\text{count(pattern, r)}$\n",
    "   - $\\text{support} = \\max_{\\text{r}} \\text{count(pattern, r)}$\n",
    "3.  **`precision`**: The precision is then calculated by dividing the `best_count` by the `total_count`. This metric indicates how reliably the pattern predicts its dominant relation.\n",
    "   - $\\text{precision} = \\frac{\\text{support}}{\\text{total}}$\n",
    "\n",
    "This calculation ensures that a rule is considered high-precision only if it consistently points to a single relation type, even if its overall frequency is moderate.\n",
    "\n",
    "\n",
    "**Rule creation criteria**\n",
    "- `precision ≥ 0.60`  \n",
    "- `support ≥ 2`\n",
    "\n",
    "Patterns passing both thresholds are converted into rules.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Rule Ranking and Representation\n",
    "\n",
    "Selected rules are sorted by:\n",
    "1. **precision** (descending)  \n",
    "2. **support** (descending)\n",
    "\n",
    "Each rule is stored as:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"name\": \"Component-Whole_PREP_of\",\n",
    "    \"relation\": \"Component-Whole\",\n",
    "    \"matcher_type\": \"lexical\",\n",
    "    \"pattern_type\": \"PREP\",\n",
    "    \"pattern_data\": [\"of\"],\n",
    "    \"precision\": 0.76,\n",
    "    \"support\": 340,\n",
    "    \"explanation\": 'Preposition \"of\" between entities'\n",
    "}\n",
    "```\n",
    "---\n",
    "### 4. Why This Approach Works\n",
    "\n",
    "* **Data-driven**: patterns come directly from labeled examples\n",
    "* **Reliable**: precision threshold ensures rules are strong predictors\n",
    "* **Flexible**: supports lexical, syntactic, and contextual signals\n",
    "* **Explainable**: every prediction includes the rule + statistics\n",
    "* **Deterministic**: no machine learning model is required at inference time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab70013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_patterns(processed_data):\n",
    "    \"\"\"\n",
    "    Mine candidate lexical and dependency patterns from labeled training data.\n",
    "\n",
    "    Args:\n",
    "        processed_data: iterable of samples, each with:\n",
    "            - 'relation': gold relation label\n",
    "            - 'doc': spaCy Doc\n",
    "            - 'e1_span', 'e2_span': entity spans\n",
    "            - 'dep_path': dependency path between entities (optional)\n",
    "\n",
    "    Returns:\n",
    "        lexical_patterns: dict[pattern_key][relation] -> count\n",
    "        dep_patterns: dict[pattern_key][relation] -> count\n",
    "    \"\"\"\n",
    "    # Group samples by relation\n",
    "    relation_groups = defaultdict(list)\n",
    "    for sample in processed_data:\n",
    "        relation_groups[sample['relation']].append(sample)\n",
    "    \n",
    "    # Track pattern occurrences: pattern_key -> {relation -> count}\n",
    "    lexical_patterns = defaultdict(lambda: defaultdict(int))\n",
    "    dep_patterns = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    print(\"Mining candidate patterns from training data...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for relation, samples in relation_groups.items():\n",
    "        print(f\"\\n{relation}: {len(samples)} samples\")\n",
    "        \n",
    "        for sample in samples:\n",
    "            doc = sample['doc']\n",
    "            e1_span = sample['e1_span']\n",
    "            e2_span = sample['e2_span']\n",
    "            \n",
    "            # Extract between-span features\n",
    "            if e1_span.start < e2_span.start:\n",
    "                between_span = doc[e1_span.end:e2_span.start]\n",
    "            else:\n",
    "                between_span = doc[e2_span.end:e1_span.start]\n",
    "            \n",
    "            # 1. LEXICAL PATTERNS: Between-span lemmas and bigrams\n",
    "            between_lemmas = [t.lemma_.lower() for t in between_span if not t.is_punct]\n",
    "            \n",
    "            # Single lemmas\n",
    "            for lemma in between_lemmas:\n",
    "                if len(lemma) > 2:\n",
    "                    pattern_key = ('LEMMA', lemma)\n",
    "                    lexical_patterns[pattern_key][relation] += 1\n",
    "            \n",
    "            # Bigrams\n",
    "            for i in range(len(between_lemmas) - 1):\n",
    "                bigram = (between_lemmas[i], between_lemmas[i+1])\n",
    "                pattern_key = ('BIGRAM', bigram)\n",
    "                lexical_patterns[pattern_key][relation] += 1\n",
    "            \n",
    "            # Prepositions (very important)\n",
    "            for token in between_span:\n",
    "                if token.pos_ == 'ADP':\n",
    "                    pattern_key = ('PREP', token.lemma_.lower())\n",
    "                    lexical_patterns[pattern_key][relation] += 1\n",
    "            \n",
    "            # Context window: word before e1 and word after e2\n",
    "            if e1_span.start > 0:\n",
    "                before_e1 = doc[e1_span.start - 1]\n",
    "                if not before_e1.is_punct and len(before_e1.lemma_) > 2:\n",
    "                    pattern_key = ('BEFORE_E1', before_e1.lemma_.lower())\n",
    "                    lexical_patterns[pattern_key][relation] += 1\n",
    "            \n",
    "            if e2_span.end < len(doc):\n",
    "                after_e2 = doc[e2_span.end]\n",
    "                if not after_e2.is_punct and len(after_e2.lemma_) > 2:\n",
    "                    pattern_key = ('AFTER_E2', after_e2.lemma_.lower())\n",
    "                    lexical_patterns[pattern_key][relation] += 1\n",
    "            \n",
    "            # Entity POS tag pattern\n",
    "            pattern_key = ('ENTITY_POS', e1_span.root.pos_, e2_span.root.pos_)\n",
    "            lexical_patterns[pattern_key][relation] += 1\n",
    "            \n",
    "            # 2. DEPENDENCY PATTERNS: e1 and e2 roles + verb\n",
    "            e1_head = e1_span.root\n",
    "            e2_head = e2_span.root\n",
    "            \n",
    "            # Find connecting verb (if any)\n",
    "            dep_path = sample['dep_path']\n",
    "            path_lemmas = [d[2] for d in dep_path] if dep_path else []\n",
    "            path_deps = [d[0] for d in dep_path] if dep_path else []\n",
    "            \n",
    "            # Look for verb in path\n",
    "            for token in doc:\n",
    "                if token.pos_ == 'VERB':\n",
    "                    # Check if this verb connects e1 and e2\n",
    "                    e1_dep_to_verb = None\n",
    "                    e2_dep_to_verb = None\n",
    "                    \n",
    "                    # Check e1 relation to verb\n",
    "                    if e1_head.head == token:\n",
    "                        e1_dep_to_verb = e1_head.dep_\n",
    "                    elif e1_head == token:\n",
    "                        e1_dep_to_verb = 'VERB_IS_E1'\n",
    "                    \n",
    "                    # Check e2 relation to verb\n",
    "                    if e2_head.head == token:\n",
    "                        e2_dep_to_verb = e2_head.dep_\n",
    "                    elif e2_head == token:\n",
    "                        e2_dep_to_verb = 'VERB_IS_E2'\n",
    "                    \n",
    "                    if e1_dep_to_verb and e2_dep_to_verb:\n",
    "                        verb_lemma = token.lemma_.lower()\n",
    "                        pattern_key = ('DEP_VERB', verb_lemma, e1_dep_to_verb, e2_dep_to_verb)\n",
    "                        dep_patterns[pattern_key][relation] += 1\n",
    "            \n",
    "            # Simpler: just e1 and e2 dependency labels\n",
    "            pattern_key = ('DEP_LABELS', e1_head.dep_, e2_head.dep_)\n",
    "            dep_patterns[pattern_key][relation] += 1\n",
    "    \n",
    "    return lexical_patterns, dep_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df9c90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_rank_patterns(lexical_patterns, dep_patterns, min_precision=0.60, min_support=2):\n",
    "    \"\"\"\n",
    "    Filter patterns by precision and support, then rank them.\n",
    "    Lower thresholds (precision=0.60, support=2) for better coverage.\n",
    "    Returns: ordered list of rule dicts\n",
    "    \"\"\"\n",
    "    rules = []\n",
    "    \n",
    "    # Process lexical patterns\n",
    "    for pattern_key, relation_counts in lexical_patterns.items():\n",
    "        total_count = sum(relation_counts.values())\n",
    "        if total_count < min_support:\n",
    "            continue\n",
    "        \n",
    "        # Find dominant relation\n",
    "        best_relation = max(relation_counts, key=relation_counts.get)\n",
    "        best_count = relation_counts[best_relation]\n",
    "        precision = best_count / total_count\n",
    "        \n",
    "        if precision >= min_precision:\n",
    "            pattern_type, *pattern_data = pattern_key\n",
    "            \n",
    "            # Create rule dict\n",
    "            rule = {\n",
    "                'name': f\"{best_relation}_{pattern_type}_{hash(pattern_key) % 10000}\",\n",
    "                'relation': best_relation,\n",
    "                'direction': 'e1,e2',  # Default direction\n",
    "                'matcher_type': 'lexical',\n",
    "                'pattern_type': pattern_type,\n",
    "                'pattern_data': pattern_data,\n",
    "                'precision': precision,\n",
    "                'support': best_count,\n",
    "                'explanation': f\"{pattern_type} pattern: {pattern_data}\"\n",
    "            }\n",
    "            rules.append(rule)\n",
    "    \n",
    "    # Process dependency patterns  \n",
    "    for pattern_key, relation_counts in dep_patterns.items():\n",
    "        total_count = sum(relation_counts.values())\n",
    "        if total_count < min_support:\n",
    "            continue\n",
    "        \n",
    "        best_relation = max(relation_counts, key=relation_counts.get)\n",
    "        best_count = relation_counts[best_relation]\n",
    "        precision = best_count / total_count\n",
    "        \n",
    "        if precision >= min_precision:\n",
    "            pattern_type, *pattern_data = pattern_key\n",
    "            \n",
    "            rule = {\n",
    "                'name': f\"{best_relation}_{pattern_type}_{hash(pattern_key) % 10000}\",\n",
    "                'relation': best_relation,\n",
    "                'direction': 'e1,e2',\n",
    "                'matcher_type': 'dependency',\n",
    "                'pattern_type': pattern_type,\n",
    "                'pattern_data': pattern_data,\n",
    "                'precision': precision,\n",
    "                'support': best_count,\n",
    "                'explanation': f\"{pattern_type}: {pattern_data}\"\n",
    "            }\n",
    "            rules.append(rule)\n",
    "    \n",
    "    # Sort by precision (descending), then support (descending)\n",
    "    rules.sort(key=lambda r: (-r['precision'], -r['support']))\n",
    "    \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a90da03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1: Mining patterns from training data...\n",
      "Mining candidate patterns from training data...\n",
      "================================================================================\n",
      "\n",
      "Component-Whole: 941 samples\n",
      "\n",
      "Other: 1410 samples\n",
      "\n",
      "Instrument-Agency: 504 samples\n",
      "\n",
      "Member-Collection: 690 samples\n",
      "\n",
      "Cause-Effect: 1003 samples\n",
      "\n",
      "Entity-Destination: 845 samples\n",
      "\n",
      "Content-Container: 540 samples\n",
      "\n",
      "Message-Topic: 634 samples\n",
      "\n",
      "Product-Producer: 717 samples\n",
      "\n",
      "Entity-Origin: 716 samples\n",
      "\n",
      "Found 16976 unique lexical pattern candidates\n",
      "Found 368 unique dependency pattern candidates\n",
      "\n",
      "Step 2: Filtering by precision ≥ 0.60 and support ≥ 2...\n",
      "\n",
      "Discovered 1841 high-quality rules\n",
      "\n",
      "Top 10 rules:\n",
      "====================================================================================================\n",
      "Relation                  Type            Precision    Support    Pattern\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Cause-Effect              LEMMA           1.000        29         ['trigger']\n",
      "Cause-Effect              BIGRAM          1.000        27         [('cause', 'of')]\n",
      "Cause-Effect              BIGRAM          1.000        25         [('trigger', 'by')]\n",
      "Cause-Effect              BIGRAM          1.000        20         [('cause', 'the')]\n",
      "Cause-Effect              BIGRAM          1.000        18         [('that', 'cause')]\n",
      "Entity-Origin             BIGRAM          1.000        15         [('arrive', 'from')]\n",
      "Instrument-Agency         BIGRAM          1.000        14         [('use', 'by')]\n",
      "Content-Container         BIGRAM          1.000        14         [('be', 'hide')]\n",
      "Content-Container         BIGRAM          1.000        14         [('hide', 'in')]\n",
      "Cause-Effect              BIGRAM          1.000        12         [('lead', 'to')]\n"
     ]
    }
   ],
   "source": [
    "# Mine patterns from training data\n",
    "print(\"\\nStep 1: Mining patterns from training data...\")\n",
    "lexical_patterns, dep_patterns = extract_candidate_patterns(train_processed)\n",
    "\n",
    "print(f\"\\nFound {len(lexical_patterns)} unique lexical pattern candidates\")\n",
    "print(f\"Found {len(dep_patterns)} unique dependency pattern candidates\")\n",
    "\n",
    "# Filter and rank patterns\n",
    "print(\"\\nStep 2: Filtering by precision ≥ 0.60 and support ≥ 2...\")\n",
    "DISCOVERED_RULES = filter_and_rank_patterns(lexical_patterns, dep_patterns, \n",
    "                                             min_precision=0.60, min_support=2)\n",
    "\n",
    "print(f\"\\nDiscovered {len(DISCOVERED_RULES)} high-quality rules\")\n",
    "print(\"\\nTop 10 rules:\")\n",
    "print(\"=\"*100)\n",
    "print(f\"{'Relation':<25} {'Type':<15} {'Precision':<12} {'Support':<10} {'Pattern'}\")\n",
    "print(\"-\"*100)\n",
    "for rule in DISCOVERED_RULES[:10]:\n",
    "    print(f\"{rule['relation']:<25} {rule['pattern_type']:<15} {rule['precision']:<12.3f} {rule['support']:<10} {str(rule['pattern_data'])[:40]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fbb34c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "TOP RULES BY RELATION TYPE (for Explainability)\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Relation: Cause-Effect (291 total rules)\n",
      "====================================================================================================\n",
      "\n",
      "  Rule 1: Cause-Effect_LEMMA_9900\n",
      "    Type: LEMMA\n",
      "    Precision: 1.000 | Support: 29\n",
      "    spaCy Pattern: [{\"LEMMA\": \"trigger\"}]\n",
      "\n",
      "  Rule 2: Cause-Effect_BIGRAM_570\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 27\n",
      "    spaCy Pattern: [{\"LEMMA\": \"cause\"}, {\"LEMMA\": \"of\"}]\n",
      "\n",
      "  Rule 3: Cause-Effect_BIGRAM_5528\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 25\n",
      "    spaCy Pattern: [{\"LEMMA\": \"trigger\"}, {\"LEMMA\": \"by\"}]\n",
      "\n",
      "====================================================================================================\n",
      "Relation: Component-Whole (128 total rules)\n",
      "====================================================================================================\n",
      "\n",
      "  Rule 1: Component-Whole_BIGRAM_6849\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 8\n",
      "    spaCy Pattern: [{\"LEMMA\": \"comprise\"}, {\"LEMMA\": \"a\"}]\n",
      "\n",
      "  Rule 2: Component-Whole_BIGRAM_242\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 7\n",
      "    spaCy Pattern: [{\"LEMMA\": \"have\"}, {\"LEMMA\": \"two\"}]\n",
      "\n",
      "  Rule 3: Component-Whole_BIGRAM_8533\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 7\n",
      "    spaCy Pattern: [{\"LEMMA\": \"good\"}, {\"LEMMA\": \"part\"}]\n",
      "\n",
      "====================================================================================================\n",
      "Relation: Content-Container (59 total rules)\n",
      "====================================================================================================\n",
      "\n",
      "  Rule 1: Content-Container_BIGRAM_1089\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 14\n",
      "    spaCy Pattern: [{\"LEMMA\": \"be\"}, {\"LEMMA\": \"hide\"}]\n",
      "\n",
      "  Rule 2: Content-Container_BIGRAM_3240\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 14\n",
      "    spaCy Pattern: [{\"LEMMA\": \"hide\"}, {\"LEMMA\": \"in\"}]\n",
      "\n",
      "  Rule 3: Content-Container_BIGRAM_1966\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 3\n",
      "    spaCy Pattern: [{\"LEMMA\": \"sit\"}, {\"LEMMA\": \"in\"}]\n",
      "\n",
      "====================================================================================================\n",
      "Relation: Entity-Destination (221 total rules)\n",
      "====================================================================================================\n",
      "\n",
      "  Rule 1: Entity-Destination_BIGRAM_8360\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 12\n",
      "    spaCy Pattern: [{\"LEMMA\": \"release\"}, {\"LEMMA\": \"into\"}]\n",
      "\n",
      "  Rule 2: Entity-Destination_BIGRAM_2871\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 10\n",
      "    spaCy Pattern: [{\"LEMMA\": \"flow\"}, {\"LEMMA\": \"into\"}]\n",
      "\n",
      "  Rule 3: Entity-Destination_BIGRAM_6566\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 10\n",
      "    spaCy Pattern: [{\"LEMMA\": \"be\"}, {\"LEMMA\": \"add\"}]\n",
      "\n",
      "====================================================================================================\n",
      "Relation: Entity-Origin (147 total rules)\n",
      "====================================================================================================\n",
      "\n",
      "  Rule 1: Entity-Origin_BIGRAM_1578\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 15\n",
      "    spaCy Pattern: [{\"LEMMA\": \"arrive\"}, {\"LEMMA\": \"from\"}]\n",
      "\n",
      "  Rule 2: Entity-Origin_BIGRAM_2592\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 8\n",
      "    spaCy Pattern: [{\"LEMMA\": \"emerge\"}, {\"LEMMA\": \"from\"}]\n",
      "\n",
      "  Rule 3: Entity-Origin_BIGRAM_2484\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 6\n",
      "    spaCy Pattern: [{\"LEMMA\": \"from\"}, {\"LEMMA\": \"previous\"}]\n",
      "\n",
      "====================================================================================================\n",
      "Relation: Instrument-Agency (172 total rules)\n",
      "====================================================================================================\n",
      "\n",
      "  Rule 1: Instrument-Agency_BIGRAM_5186\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 14\n",
      "    spaCy Pattern: [{\"LEMMA\": \"use\"}, {\"LEMMA\": \"by\"}]\n",
      "\n",
      "  Rule 2: Instrument-Agency_LEMMA_2414\n",
      "    Type: LEMMA\n",
      "    Precision: 1.000 | Support: 9\n",
      "    spaCy Pattern: [{\"LEMMA\": \"wield\"}]\n",
      "\n",
      "  Rule 3: Instrument-Agency_DEP_VERB_565\n",
      "    Type: DEP_VERB\n",
      "    Precision: 1.000 | Support: 7\n",
      "    spaCy Pattern: \n",
      "            DependencyMatcher Pattern:\n",
      "            [\n",
      "                {\n",
      "                    \"RIGHT_ID\": \"verb\",\n",
      "                    \"RIGHT_ATTRS\": {\"LEMMA\": \"wield\", \"POS\": \"VERB\"}\n",
      "                },\n",
      "                {\n",
      "                    \"LEFT_ID\": \"verb\",\n",
      "                    \"REL_OP\": \">\",  \n",
      "                    \"RIGHT_ID\": \"e1\",\n",
      "                    \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
      "                },\n",
      "                {\n",
      "                    \"LEFT_ID\": \"verb\",\n",
      "                    \"REL_OP\": \">\",  # verb is head of e2\n",
      "                    \"RIGHT_ID\": \"e2\",\n",
      "                    \"RIGHT_ATTRS\": {\"DEP\": \"dobj\"}\n",
      "                }\n",
      "            ]\n",
      "\n",
      "====================================================================================================\n",
      "Relation: Member-Collection (65 total rules)\n",
      "====================================================================================================\n",
      "\n",
      "  Rule 1: Member-Collection_LEMMA_8805\n",
      "    Type: LEMMA\n",
      "    Precision: 1.000 | Support: 3\n",
      "    spaCy Pattern: [{\"LEMMA\": \"baby\"}]\n",
      "\n",
      "  Rule 2: Member-Collection_BIGRAM_8090\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 3\n",
      "    spaCy Pattern: [{\"LEMMA\": \"of\"}, {\"LEMMA\": \"seven\"}]\n",
      "\n",
      "  Rule 3: Member-Collection_BIGRAM_364\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 3\n",
      "    spaCy Pattern: [{\"LEMMA\": \"of\"}, {\"LEMMA\": \"senior\"}]\n",
      "\n",
      "====================================================================================================\n",
      "Relation: Message-Topic (327 total rules)\n",
      "====================================================================================================\n",
      "\n",
      "  Rule 1: Message-Topic_LEMMA_9814\n",
      "    Type: LEMMA\n",
      "    Precision: 1.000 | Support: 10\n",
      "    spaCy Pattern: [{\"LEMMA\": \"detail\"}]\n",
      "\n",
      "  Rule 2: Message-Topic_LEMMA_9578\n",
      "    Type: LEMMA\n",
      "    Precision: 1.000 | Support: 9\n",
      "    spaCy Pattern: [{\"LEMMA\": \"define\"}]\n",
      "\n",
      "  Rule 3: Message-Topic_LEMMA_4799\n",
      "    Type: LEMMA\n",
      "    Precision: 1.000 | Support: 9\n",
      "    spaCy Pattern: [{\"LEMMA\": \"explore\"}]\n",
      "\n",
      "====================================================================================================\n",
      "Relation: Other (238 total rules)\n",
      "====================================================================================================\n",
      "\n",
      "  Rule 1: Other_LEMMA_2135\n",
      "    Type: LEMMA\n",
      "    Precision: 1.000 | Support: 8\n",
      "    spaCy Pattern: [{\"LEMMA\": \"denote\"}]\n",
      "\n",
      "  Rule 2: Other_BEFORE_E1_9874\n",
      "    Type: BEFORE_E1\n",
      "    Precision: 1.000 | Support: 6\n",
      "    spaCy Pattern: Word before E1: {\"LEMMA\": \"tree\"}\n",
      "\n",
      "  Rule 3: Other_LEMMA_5665\n",
      "    Type: LEMMA\n",
      "    Precision: 1.000 | Support: 5\n",
      "    spaCy Pattern: [{\"LEMMA\": \"participant\"}]\n",
      "\n",
      "====================================================================================================\n",
      "Relation: Product-Producer (193 total rules)\n",
      "====================================================================================================\n",
      "\n",
      "  Rule 1: Product-Producer_BIGRAM_8940\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 11\n",
      "    spaCy Pattern: [{\"LEMMA\": \"create\"}, {\"LEMMA\": \"the\"}]\n",
      "\n",
      "  Rule 2: Product-Producer_DEP_VERB_6329\n",
      "    Type: DEP_VERB\n",
      "    Precision: 1.000 | Support: 8\n",
      "    spaCy Pattern: \n",
      "            DependencyMatcher Pattern:\n",
      "            [\n",
      "                {\n",
      "                    \"RIGHT_ID\": \"verb\",\n",
      "                    \"RIGHT_ATTRS\": {\"LEMMA\": \"write\", \"POS\": \"VERB\"}\n",
      "                },\n",
      "                {\n",
      "                    \"LEFT_ID\": \"verb\",\n",
      "                    \"REL_OP\": \">\",  \n",
      "                    \"RIGHT_ID\": \"e1\",\n",
      "                    \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
      "                },\n",
      "                {\n",
      "                    \"LEFT_ID\": \"verb\",\n",
      "                    \"REL_OP\": \">\",  # verb is head of e2\n",
      "                    \"RIGHT_ID\": \"e2\",\n",
      "                    \"RIGHT_ATTRS\": {\"DEP\": \"dobj\"}\n",
      "                }\n",
      "            ]\n",
      "\n",
      "  Rule 3: Product-Producer_BIGRAM_3977\n",
      "    Type: BIGRAM\n",
      "    Precision: 1.000 | Support: 6\n",
      "    spaCy Pattern: [{\"LEMMA\": \"dig\"}, {\"LEMMA\": \"a\"}]\n"
     ]
    }
   ],
   "source": [
    "# Visualize rules by relation for explainability\n",
    "def visualize_rules_by_relation(rules, top_n=5):\n",
    "    \"\"\"\n",
    "    Display the top-N highest precision rules for each relation.\n",
    "\n",
    "    Note:\n",
    "        `rules` is already be sorted globally by (precision desc, support desc) as produced by `filter_and_rank_patterns()`.\n",
    "        \n",
    "        Because of this, taking the first N rules in each relation group\n",
    "        truly reflects the strongest patterns for that relation.\n",
    "\n",
    "    This function does not re-sort; it only groups and prints the top rules.\n",
    "    \"\"\"\n",
    "    relation_rules = defaultdict(list)\n",
    "    \n",
    "    for rule in rules:\n",
    "        relation_rules[rule['relation']].append(rule)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"TOP RULES BY RELATION TYPE (for Explainability)\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    for relation in sorted(relation_rules.keys()):\n",
    "        rules_list = relation_rules[relation][:top_n]\n",
    "        print(f\"\\n{'='*100}\")\n",
    "        print(f\"Relation: {relation} ({len(relation_rules[relation])} total rules)\")\n",
    "        print(f\"{'='*100}\")\n",
    "        \n",
    "        for i, rule in enumerate(rules_list, 1):\n",
    "            print(f\"\\n  Rule {i}: {rule['name']}\")\n",
    "            print(f\"    Type: {rule['pattern_type']}\")\n",
    "            print(f\"    Precision: {rule['precision']:.3f} | Support: {rule['support']}\")\n",
    "            \n",
    "            # Convert to spaCy Matcher syntax\n",
    "            pattern_type = rule['pattern_type']\n",
    "            pattern_data = rule['pattern_data']\n",
    "            \n",
    "            if pattern_type == 'LEMMA':\n",
    "                spacy_pattern = f'[{{\"LEMMA\": \"{pattern_data[0]}\"}}]'\n",
    "            elif pattern_type == 'BIGRAM':\n",
    "                spacy_pattern = f'[{{\"LEMMA\": \"{pattern_data[0][0]}\"}}, {{\"LEMMA\": \"{pattern_data[0][1]}\"}}]'\n",
    "            elif pattern_type == 'PREP':\n",
    "                spacy_pattern = f'[{{\"LEMMA\": \"{pattern_data[0]}\", \"POS\": \"ADP\"}}]'\n",
    "            elif pattern_type == 'BEFORE_E1':\n",
    "                spacy_pattern = f'Word before E1: {{\"LEMMA\": \"{pattern_data[0]}\"}}'\n",
    "            elif pattern_type == 'AFTER_E2':\n",
    "                spacy_pattern = f'Word after E2: {{\"LEMMA\": \"{pattern_data[0]}\"}}'\n",
    "            elif pattern_type == 'ENTITY_POS':\n",
    "                spacy_pattern = f'E1.pos_==\"{pattern_data[0]}\" AND E2.pos_==\"{pattern_data[1]}\"'\n",
    "            elif pattern_type == 'DEP_VERB':\n",
    "                verb, e1_dep, e2_dep = pattern_data\n",
    "                # Show structured DependencyMatcher pattern\n",
    "                # REL_OPs are \">\" indicating head relations\n",
    "                spacy_pattern = f'''\n",
    "            DependencyMatcher Pattern:\n",
    "            [\n",
    "                {{\n",
    "                    \"RIGHT_ID\": \"verb\",\n",
    "                    \"RIGHT_ATTRS\": {{\"LEMMA\": \"{verb}\", \"POS\": \"VERB\"}}\n",
    "                }},\n",
    "                {{\n",
    "                    \"LEFT_ID\": \"verb\",\n",
    "                    \"REL_OP\": \">\",  \n",
    "                    \"RIGHT_ID\": \"e1\",\n",
    "                    \"RIGHT_ATTRS\": {{\"DEP\": \"{e1_dep}\"}}\n",
    "                }},\n",
    "                {{\n",
    "                    \"LEFT_ID\": \"verb\",\n",
    "                    \"REL_OP\": \">\",  # verb is head of e2\n",
    "                    \"RIGHT_ID\": \"e2\",\n",
    "                    \"RIGHT_ATTRS\": {{\"DEP\": \"{e2_dep}\"}}\n",
    "                }}\n",
    "            ]'''\n",
    "            elif pattern_type == 'DEP_LABELS':\n",
    "                spacy_pattern = f'E1.dep_==\"{pattern_data[0]}\" AND E2.dep_==\"{pattern_data[1]}\"'\n",
    "            else:\n",
    "                spacy_pattern = str(pattern_data)\n",
    "            \n",
    "            print(f\"    spaCy Pattern: {spacy_pattern}\")\n",
    "\n",
    "visualize_rules_by_relation(DISCOVERED_RULES, top_n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5491ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_relation_features(processed_data):\n",
    "    \"\"\"\n",
    "    Analyze linguistic features for each relation type.\n",
    "\n",
    "    Each sample in `processed_data` is expected to contain:\n",
    "        - 'relation': gold relation label (str)\n",
    "        - 'doc': spaCy Doc\n",
    "        - 'e1_span', 'e2_span': spaCy spans for the two entities\n",
    "        - 'dep_path': list of (dep_label, ...) along shortest path (optional)\n",
    "        - 'between_words': list of dicts with 'text' and 'lemma'\n",
    "\n",
    "    Returns:\n",
    "        dict[relation] -> {\n",
    "            'count': int,\n",
    "            'top_lemmas': [(lemma, freq)],\n",
    "            'top_verbs': [(lemma, freq)],\n",
    "            'top_preps': [(lemma, freq)],\n",
    "            'top_dep_paths': [(path_tuple, freq)],\n",
    "            'top_between_words': [(lemma, freq)]\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Group by relation type\n",
    "    relation_groups = defaultdict(list)\n",
    "    for sample in processed_data:\n",
    "        relation_groups[sample['relation']].append(sample)\n",
    "    \n",
    "    # Analyze each relation\n",
    "    relation_analysis = {}\n",
    "    \n",
    "    for relation, samples in relation_groups.items():\n",
    "        # Collect features from all samples of this relation\n",
    "        all_lemmas = []\n",
    "        all_verbs = []\n",
    "        all_preps = []\n",
    "        all_dep_paths = []\n",
    "        all_between_words = []\n",
    "        \n",
    "        for sample in samples:\n",
    "            doc = sample['doc']\n",
    "            \n",
    "            # Collect lemmas (excluding entities)\n",
    "            e1_tokens = set(range(sample['e1_span'].start, sample['e1_span'].end))\n",
    "            e2_tokens = set(range(sample['e2_span'].start, sample['e2_span'].end))\n",
    "            \n",
    "            for token in doc:\n",
    "                if token.i not in e1_tokens and token.i not in e2_tokens:\n",
    "                    lemma = token.lemma_.lower()\n",
    "                    \n",
    "                    # Collect verbs (don't filter stopwords for verbs)\n",
    "                    if token.pos_ == 'VERB' and not token.is_punct and len(lemma) > 2:\n",
    "                        all_verbs.append(lemma)\n",
    "                    \n",
    "                    # Collect prepositions (INCLUDE stopwords like \"of\", \"in\", \"at\")\n",
    "                    if token.pos_ == 'ADP' and not token.is_punct:\n",
    "                        all_preps.append(lemma)\n",
    "                    \n",
    "                    # Collect other lemmas (filter stopwords for general keywords)\n",
    "                    if not token.is_stop and not token.is_punct and len(lemma) > 2:\n",
    "                        all_lemmas.append(lemma)\n",
    "            \n",
    "            # Collect dependency paths (sequence of dependency labels along shortest path)\n",
    "            if sample['dep_path']:\n",
    "                path_deps = tuple([d[0] for d in sample['dep_path']])\n",
    "                all_dep_paths.append(path_deps)\n",
    "            \n",
    "            # Between words (fixed: should be \"if word['text'].strip()\" not \"if not\")\n",
    "            for word in sample['between_words']:\n",
    "                if word['text'].strip() and len(word['lemma']) > 2:\n",
    "                    all_between_words.append(word['lemma'].lower())\n",
    "        \n",
    "        # Count frequencies\n",
    "        lemma_freq = Counter(all_lemmas).most_common(30)\n",
    "        verb_freq = Counter(all_verbs).most_common(15)\n",
    "        prep_freq = Counter(all_preps).most_common(10)\n",
    "        dep_path_freq = Counter(all_dep_paths).most_common(10)\n",
    "        between_freq = Counter(all_between_words).most_common(20)\n",
    "        \n",
    "        relation_analysis[relation] = {\n",
    "            'count': len(samples),\n",
    "            'top_lemmas': lemma_freq,\n",
    "            'top_verbs': verb_freq,\n",
    "            'top_preps': prep_freq,\n",
    "            'top_dep_paths': dep_path_freq,\n",
    "            'top_between_words': between_freq\n",
    "        }\n",
    "    \n",
    "    return relation_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbe0912",
   "metadata": {},
   "source": [
    "## 5. Deterministic Rule Application Engine\n",
    "\n",
    "Now we implement the core rule application logic using:\n",
    "\n",
    "- **spaCy Matcher**: For single-token and sequence patterns (LEMMA, BIGRAM, PREP).  \n",
    "- **spaCy PhraseMatcher**: For efficient matching of lemma-based patterns.  \n",
    "- **spaCy DependencyMatcher**: For dependency-based patterns (DEP_VERB).\n",
    "\n",
    "This follows spaCy’s recommended practice for rule-based matching.\n",
    "\n",
    "---\n",
    "### How does it work?\n",
    "\n",
    "Rules are pre-sorted by (precision desc, support desc),\n",
    "e.g. via `filter_and_rank_patterns()`. \n",
    "- We iterate them in order and stop at the first matching rule, which gives a deterministic\n",
    "decision-list classifier (\"first high-precision rule wins\").\n",
    "\n",
    "---\n",
    "\n",
    "The function `apply_rule_based_classifier` applies the discovered rules to each\n",
    "sentence using spaCy’s rule-based matchers. At the beginning of the function, we\n",
    "pre-compile all rule patterns into three matcher objects:\n",
    "\n",
    "- `Matcher`\n",
    "- `PhraseMatcher`\n",
    "- `DependencyMatcher`\n",
    "\n",
    "These matchers serve as efficient pattern detectors over the spaCy `Doc`.\n",
    "\n",
    "During classification (the main loop), each sample is processed by iterating\n",
    "through the rules in ranked order (highest precision first). For each rule, the\n",
    "corresponding matcher is applied:\n",
    "\n",
    "- Token and phrase patterns are matched against the *between-entity* span.\n",
    "- Dependency patterns are matched against the entire sentence.\n",
    "- Context and POS rules are checked with simple Python conditions.\n",
    "\n",
    "As soon as a rule’s pattern matches, that rule becomes the prediction\n",
    "(\"first-match-wins\" decision list). The function records the predicted relation,\n",
    "the argument direction, and a human-readable explanation including the rule’s\n",
    "precision and support. If no rule matches, the instance is labeled `\"Other\"`.\n",
    "\n",
    "This preserves deterministic behavior and full explainability while using spaCy\n",
    "only as a fast pattern-matching backend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e6c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher, PhraseMatcher, DependencyMatcher\n",
    "\n",
    "def apply_rule_based_classifier(samples, rules, nlp):\n",
    "    \"\"\"\n",
    "    Apply rule-based classification using spaCy's proper matchers:\n",
    "    - Matcher: for token sequences (LEMMA, BIGRAM, PREP)\n",
    "    - PhraseMatcher: for efficient phrase matching (LEMMA lists)\n",
    "    - DependencyMatcher: for dependency patterns (DEP_VERB)\n",
    "    \n",
    "    This follows spaCy documentation best practices.\n",
    "    \"\"\"\n",
    "    # Pre-compile all matchers\n",
    "    token_matcher = Matcher(nlp.vocab)\n",
    "    phrase_matcher = PhraseMatcher(nlp.vocab, attr=\"LEMMA\")\n",
    "    dep_matcher = DependencyMatcher(nlp.vocab)\n",
    "    \n",
    "    # # Map match IDs back to rules\n",
    "    # rule_lookup = {}  # match_id -> rule\n",
    "    \n",
    "    # === 1. Compile Token Patterns (BIGRAM, PREP) ===\n",
    "    for i, rule in enumerate(rules):\n",
    "        match_id = f\"rule_{i}\"\n",
    "        # rule_lookup[match_id] = rule\n",
    "        \n",
    "        if rule['matcher_type'] == 'lexical':\n",
    "            pattern_type = rule['pattern_type']\n",
    "            pattern_data = rule['pattern_data']\n",
    "            \n",
    "            if pattern_type == 'BIGRAM':\n",
    "                pattern = [{\"LEMMA\": pattern_data[0][0]}, {\"LEMMA\": pattern_data[0][1]}]\n",
    "                token_matcher.add(match_id, [pattern])\n",
    "            \n",
    "            elif pattern_type == 'PREP':\n",
    "                pattern = [{\"LEMMA\": pattern_data[0], \"POS\": \"ADP\"}]\n",
    "                token_matcher.add(match_id, [pattern])\n",
    "    \n",
    "    # === 2. Compile Phrase Patterns (LEMMA) - More efficient ===\n",
    "    lemma_rules = [(i, r) for i, r in enumerate(rules) \n",
    "                   if r['matcher_type'] == 'lexical' and r['pattern_type'] == 'LEMMA']\n",
    "    \n",
    "    if lemma_rules:\n",
    "        # Create Doc patterns with full pipeline to get lemmas\n",
    "        # Use nlp() instead of nlp.make_doc() when attr=\"LEMMA\" is needed\n",
    "        patterns = [nlp(r['pattern_data'][0]) for _, r in lemma_rules]\n",
    "        match_ids = [f\"rule_{i}\" for i, _ in lemma_rules]\n",
    "        \n",
    "        for match_id, pattern in zip(match_ids, patterns):\n",
    "            phrase_matcher.add(match_id, [pattern])\n",
    "    \n",
    "    # === 3. Compile Dependency Patterns (DEP_VERB) ===\n",
    "    for i, rule in enumerate(rules):\n",
    "        if rule['pattern_type'] == 'DEP_VERB':\n",
    "            match_id = f\"rule_{i}\"\n",
    "            verb_lemma, e1_dep, e2_dep = rule['pattern_data']\n",
    "            \n",
    "            # Build DependencyMatcher pattern\n",
    "            pattern = [\n",
    "                # Anchor: the verb\n",
    "                {\n",
    "                    \"RIGHT_ID\": \"verb\",\n",
    "                    \"RIGHT_ATTRS\": {\"LEMMA\": verb_lemma, \"POS\": \"VERB\"}\n",
    "                },\n",
    "                # E1 connected to verb\n",
    "                {\n",
    "                    \"LEFT_ID\": \"verb\",\n",
    "                    \"REL_OP\": \">\",  # verb is head of e1\n",
    "                    \"RIGHT_ID\": \"e1\",\n",
    "                    \"RIGHT_ATTRS\": {\"DEP\": e1_dep}\n",
    "                },\n",
    "                # E2 connected to verb\n",
    "                {\n",
    "                    \"LEFT_ID\": \"verb\",\n",
    "                    \"REL_OP\": \">\",  # verb is head of e2\n",
    "                    \"RIGHT_ID\": \"e2\",\n",
    "                    \"RIGHT_ATTRS\": {\"DEP\": e2_dep}\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            dep_matcher.add(match_id, [pattern])\n",
    "    \n",
    "    # === 4. Apply Matchers to Samples ===\n",
    "    predictions, directions, explanations = [], [], []\n",
    "    \n",
    "    for sample in tqdm(samples, desc=\"Classifying\"):\n",
    "        doc = sample['doc']\n",
    "        e1_span, e2_span = sample['e1_span'], sample['e2_span']\n",
    "        between_span = doc[e1_span.end:e2_span.start] if e1_span.start < e2_span.start else doc[e2_span.end:e1_span.start]\n",
    "        e1_head, e2_head = e1_span.root, e2_span.root\n",
    "        \n",
    "        matched_rule = None\n",
    "        \n",
    "        # Apply rules in order (iterate through rules to maintain priority)\n",
    "        for i, rule in enumerate(rules):\n",
    "            match_id = f\"rule_{i}\"\n",
    "            pattern_type = rule['pattern_type']\n",
    "            pattern_data = rule['pattern_data']\n",
    "            \n",
    "            # === Token Matcher (BIGRAM, PREP) ===\n",
    "            if pattern_type in ['BIGRAM', 'PREP']:\n",
    "                matches = token_matcher(between_span)\n",
    "                if any(nlp.vocab.strings[m[0]] == match_id for m in matches):\n",
    "                    matched_rule = rule\n",
    "                    break\n",
    "            \n",
    "            # === Phrase Matcher (LEMMA) ===\n",
    "            elif pattern_type == 'LEMMA':\n",
    "                matches = phrase_matcher(between_span)\n",
    "                if any(nlp.vocab.strings[m[0]] == match_id for m in matches):\n",
    "                    matched_rule = rule\n",
    "                    break\n",
    "            \n",
    "            # === Dependency Matcher (DEP_VERB) ===\n",
    "            elif pattern_type == 'DEP_VERB':\n",
    "                matches = dep_matcher(doc)\n",
    "                # Check if match involves our entities\n",
    "                for match_id_found, token_ids in matches:\n",
    "                    if nlp.vocab.strings[match_id_found] == match_id:\n",
    "                        # Verify entities are involved in match\n",
    "                        e1_in_match = any(t in range(e1_span.start, e1_span.end) for t in token_ids)\n",
    "                        e2_in_match = any(t in range(e2_span.start, e2_span.end) for t in token_ids)\n",
    "                        if e1_in_match or e2_in_match:\n",
    "                            matched_rule = rule\n",
    "                            break\n",
    "                if matched_rule:\n",
    "                    break\n",
    "            \n",
    "            # === Context Patterns (Manual checks) ===\n",
    "            elif pattern_type == 'BEFORE_E1' and e1_span.start > 0:\n",
    "                if doc[e1_span.start - 1].lemma_.lower() == pattern_data[0]:\n",
    "                    matched_rule = rule\n",
    "                    break\n",
    "            \n",
    "            elif pattern_type == 'AFTER_E2' and e2_span.end < len(doc):\n",
    "                if doc[e2_span.end].lemma_.lower() == pattern_data[0]:\n",
    "                    matched_rule = rule\n",
    "                    break\n",
    "            \n",
    "            # === Entity POS Pattern ===\n",
    "            elif pattern_type == 'ENTITY_POS':\n",
    "                if e1_head.pos_ == pattern_data[0] and e2_head.pos_ == pattern_data[1]:\n",
    "                    matched_rule = rule\n",
    "                    break\n",
    "            \n",
    "            # === Simple Dependency Labels ===\n",
    "            elif pattern_type == 'DEP_LABELS':\n",
    "                if e1_head.dep_ == pattern_data[0] and e2_head.dep_ == pattern_data[1]:\n",
    "                    matched_rule = rule\n",
    "                    break\n",
    "        \n",
    "        # Record prediction\n",
    "        if matched_rule:\n",
    "            predictions.append(matched_rule['relation'])\n",
    "            directions.append(matched_rule['direction'])\n",
    "            explanations.append(f\"Rule {matched_rule['name']}: {matched_rule['explanation']} (precision={matched_rule['precision']:.2f}, support={matched_rule['support']})\")\n",
    "        else:\n",
    "            predictions.append('Other')\n",
    "            directions.append('e1,e2')\n",
    "            explanations.append('No high-precision rule matched; defaulting to Other.')\n",
    "    \n",
    "    return predictions, directions, explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5f27542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing rule-based classifier on sample sentences...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying: 100%|██████████| 5/5 [00:00<00:00,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1:\n",
      "Text: The system as described above has its greatest application in an arrayed configuration of antenna el...\n",
      "E1: 'configuration' | E2: 'elements'\n",
      "True: Component-Whole\n",
      "Predicted: Other\n",
      "Explanation: No high-precision rule matched; defaulting to Other.\n",
      "Match: ✗\n",
      "\n",
      "Sample 2:\n",
      "Text: The child was carefully wrapped and bound into the cradle by means of a cord....\n",
      "E1: 'child' | E2: 'cradle'\n",
      "True: Other\n",
      "Predicted: Entity-Destination\n",
      "Explanation: Rule Entity-Destination_BIGRAM_9249: BIGRAM pattern: [('into', 'the')] (precision=0.91, support=267)\n",
      "Match: ✗\n",
      "\n",
      "Sample 3:\n",
      "Text: The author of a keygen uses a disassembler to look at the raw assembly code....\n",
      "E1: 'author' | E2: 'disassembler'\n",
      "True: Instrument-Agency\n",
      "Predicted: Instrument-Agency\n",
      "Explanation: Rule Instrument-Agency_DEP_VERB_8188: DEP_VERB: ['use', 'nsubj', 'dobj'] (precision=0.87, support=45)\n",
      "Match: ✓\n",
      "\n",
      "Sample 4:\n",
      "Text: A misty ridge uprises from the surge....\n",
      "E1: 'ridge' | E2: 'surge'\n",
      "True: Other\n",
      "Predicted: Other\n",
      "Explanation: Rule Other_LEMMA_4582: LEMMA pattern: ['uprise'] (precision=0.67, support=2)\n",
      "Match: ✓\n",
      "\n",
      "Sample 5:\n",
      "Text: The student association is the voice of the undergraduate student population of the State University...\n",
      "E1: 'student' | E2: 'association'\n",
      "True: Member-Collection\n",
      "Predicted: Other\n",
      "Explanation: No high-precision rule matched; defaulting to Other.\n",
      "Match: ✗\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the rule-based classifier on a few samples\n",
    "print(\"Testing rule-based classifier on sample sentences...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Quick test on 5 samples\n",
    "test_samples = train_processed[:5]\n",
    "test_preds, test_dirs, test_expls = apply_rule_based_classifier(test_samples, DISCOVERED_RULES, nlp)\n",
    "\n",
    "for i, (sample, relation, explanation) in enumerate(zip(test_samples, test_preds, test_expls)):\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"Text: {sample['text'][:100]}...\")\n",
    "    print(f\"E1: '{sample['e1_span'].text}' | E2: '{sample['e2_span'].text}'\")\n",
    "    print(f\"True: {sample['relation']}\")\n",
    "    print(f\"Predicted: {relation}\")\n",
    "    print(f\"Explanation: {explanation}\")\n",
    "    print(f\"Match: {'✓' if relation == sample['relation'] else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f169e6",
   "metadata": {},
   "source": [
    "**Generate Predictions Using the Rule-Based Classifier**\n",
    "\n",
    "We evaluate the discovered rules by applying the deterministic rule engine\n",
    "to the processed datasets. The function `apply_rule_based_classifier`:\n",
    "\n",
    "1. Pre-compiles all rules into spaCy matchers (token, phrase, dependency).\n",
    "2. For each sample, checks the rules in ranked order (by precision).\n",
    "3. Stops at the first matching rule (\"decision list\" behavior).\n",
    "4. Returns the predicted relation and the explanation of the rule that fired.\n",
    "\n",
    "This gives fully explainable predictions for every instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecb4b14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying: 100%|██████████| 8000/8000 [16:32<00:00,  8.06it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying: 100%|██████████| 2717/2717 [05:46<00:00,  7.84it/s]\n",
      "Classifying: 100%|██████████| 2717/2717 [05:46<00:00,  7.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions using the simplified rule-based classifier\n",
    "print(\"Evaluating on training set...\")\n",
    "train_predictions, train_directions, train_explanations = apply_rule_based_classifier(train_processed, DISCOVERED_RULES, nlp)\n",
    "train_true = [s['relation'] for s in train_processed]\n",
    "\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_predictions, test_directions, test_explanations = apply_rule_based_classifier(test_processed, DISCOVERED_RULES, nlp)\n",
    "test_true = [s['relation'] for s in test_processed]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6401adf7",
   "metadata": {},
   "source": [
    "## 6. Evaluation with Deterministic Rules\n",
    "\n",
    "---\n",
    "\n",
    "We now evaluate the performance of the deterministic rule-based classifier on\n",
    "both the training and test sets. For each split, we compute:\n",
    "\n",
    "- **Accuracy** – overall correctness of predictions.\n",
    "- **Per-class precision, recall, and F1-score** – to show how well the rules\n",
    "  capture each relation category.\n",
    "- **Support** – number of samples per class.\n",
    "\n",
    "This gives a clear picture of how well the learned rules generalize to unseen\n",
    "data and which relations are easy or difficult for the rule-based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b29b887d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DETERMINISTIC RULE-BASED SYSTEM EVALUATION\n",
      "================================================================================\n",
      "\n",
      "### TRAINING SET RESULTS ###\n",
      "\n",
      "Accuracy: 0.605\n",
      "\n",
      "Per-class metrics:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "      Cause-Effect       0.83      0.76      0.79      1003\n",
      "   Component-Whole       0.71      0.33      0.46       941\n",
      " Content-Container       0.73      0.72      0.73       540\n",
      "Entity-Destination       0.80      0.87      0.83       845\n",
      "     Entity-Origin       0.81      0.63      0.71       716\n",
      " Instrument-Agency       0.74      0.62      0.67       504\n",
      " Member-Collection       0.87      0.18      0.30       690\n",
      "     Message-Topic       0.79      0.81      0.80       634\n",
      "             Other       0.30      0.62      0.41      1410\n",
      "  Product-Producer       0.72      0.51      0.60       717\n",
      "\n",
      "          accuracy                           0.61      8000\n",
      "         macro avg       0.73      0.61      0.63      8000\n",
      "      weighted avg       0.70      0.61      0.61      8000\n",
      "\n",
      "================================================================================\n",
      "\n",
      "### TEST SET RESULTS ###\n",
      "\n",
      "Accuracy: 0.521\n",
      "\n",
      "Per-class metrics:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "      Cause-Effect      0.796     0.796     0.796       328\n",
      "   Component-Whole      0.490     0.228     0.311       312\n",
      " Content-Container      0.665     0.724     0.693       192\n",
      "Entity-Destination      0.729     0.829     0.776       292\n",
      "     Entity-Origin      0.791     0.574     0.665       258\n",
      " Instrument-Agency      0.535     0.436     0.481       156\n",
      " Member-Collection      0.551     0.116     0.191       233\n",
      "     Message-Topic      0.694     0.686     0.690       261\n",
      "             Other      0.217     0.449     0.292       454\n",
      "  Product-Producer      0.539     0.329     0.409       231\n",
      "\n",
      "          accuracy                          0.521      2717\n",
      "         macro avg      0.601     0.517     0.530      2717\n",
      "      weighted avg      0.579     0.521     0.521      2717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DETERMINISTIC RULE-BASED SYSTEM EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Training set evaluation\n",
    "print(\"\\n### TRAINING SET RESULTS ###\\n\")\n",
    "train_accuracy = accuracy_score(train_true, train_predictions)\n",
    "print(f\"Accuracy: {train_accuracy:.3f}\")\n",
    "\n",
    "print(\"\\nPer-class metrics:\")\n",
    "print(classification_report(train_true, train_predictions, zero_division=0))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test set evaluation\n",
    "print(\"\\n### TEST SET RESULTS ###\\n\")\n",
    "test_accuracy = accuracy_score(test_true, test_predictions)\n",
    "print(f\"Accuracy: {test_accuracy:.3f}\")\n",
    "\n",
    "print(\"\\nPer-class metrics:\")\n",
    "print(classification_report(test_true, test_predictions, zero_division=0, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3f3f3",
   "metadata": {},
   "source": [
    "**Rule Diagnostics and Summary Statistics**\n",
    "\n",
    "To better understand the behavior of the discovered rules, we compute several\n",
    "diagnostic statistics:\n",
    "\n",
    "- **Number of rules per relation** – shows how many high-precision patterns were\n",
    "  learned for each class.\n",
    "- **Average precision and support** – summarize the overall quality of the\n",
    "  rule set. Higher precision indicates more reliable rules; higher support\n",
    "  indicates patterns that appear frequently in training data.\n",
    "- **Macro-averaged F1 and accuracy** – provide a global summary of system\n",
    "  performance on both training and test sets.\n",
    "\n",
    "These diagnostics help identify relations that are well-covered by rules and\n",
    "those that may need additional patterns or refinement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40154711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RULE DIAGNOSTICS\n",
      "================================================================================\n",
      "\n",
      "Rules discovered per relation:\n",
      "Relation                       Number of Rules\n",
      "--------------------------------------------------\n",
      "Cause-Effect                   291\n",
      "Component-Whole                128\n",
      "Content-Container              59\n",
      "Entity-Destination             221\n",
      "Entity-Origin                  147\n",
      "Instrument-Agency              172\n",
      "Member-Collection              65\n",
      "Message-Topic                  327\n",
      "Other                          238\n",
      "Product-Producer               193\n",
      "\n",
      "Total rules: 1841\n",
      "Average precision: 0.868\n",
      "Average support: 6.3\n",
      "\n",
      "Metric                         Test Set        Train Set      \n",
      "------------------------------------------------------------\n",
      "Macro-averaged Precision       0.601           0.729          \n",
      "Macro-averaged Recall          0.517           0.605          \n",
      "Macro-averaged F1              0.530           0.628          \n",
      "Accuracy                       0.521           0.605          \n",
      "\n",
      "Metric                         Test Set        Train Set      \n",
      "------------------------------------------------------------\n",
      "Macro-averaged Precision       0.601           0.729          \n",
      "Macro-averaged Recall          0.517           0.605          \n",
      "Macro-averaged F1              0.530           0.628          \n",
      "Accuracy                       0.521           0.605          \n"
     ]
    }
   ],
   "source": [
    "# Rule statistics and diagnostics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RULE DIAGNOSTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Count rules per relation\n",
    "relation_rule_counts = defaultdict(int)\n",
    "for rule in DISCOVERED_RULES:\n",
    "    relation_rule_counts[rule['relation']] += 1\n",
    "\n",
    "print(\"\\nRules discovered per relation:\")\n",
    "print(f\"{'Relation':<30} {'Number of Rules'}\")\n",
    "print(\"-\"*50)\n",
    "for relation in sorted(relation_rule_counts.keys()):\n",
    "    print(f\"{relation:<30} {relation_rule_counts[relation]}\")\n",
    "\n",
    "print(f\"\\nTotal rules: {len(DISCOVERED_RULES)}\")\n",
    "print(f\"Average precision: {np.mean([r['precision'] for r in DISCOVERED_RULES]):.3f}\")\n",
    "print(f\"Average support: {np.mean([r['support'] for r in DISCOVERED_RULES]):.1f}\")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# ========= Macro-averaged metrics =========\n",
    "test_macro_precision  = precision_score(test_true,  test_predictions,\n",
    "                                        average='macro', zero_division=0)\n",
    "train_macro_precision = precision_score(train_true, train_predictions,\n",
    "                                        average='macro', zero_division=0)\n",
    "\n",
    "test_macro_recall  = recall_score(test_true,  test_predictions,\n",
    "                                  average='macro', zero_division=0)\n",
    "train_macro_recall = recall_score(train_true, train_predictions,\n",
    "                                  average='macro', zero_division=0)\n",
    "\n",
    "test_macro_f1  = f1_score(test_true,  test_predictions,\n",
    "                          average='macro', zero_division=0)\n",
    "train_macro_f1 = f1_score(train_true, train_predictions,\n",
    "                          average='macro', zero_division=0)\n",
    "\n",
    "# `test_accuracy` and `train_accuracy` assumed pre-computed\n",
    "\n",
    "# ========= Summary table (Train vs Test) =========\n",
    "print(f\"\\n{'Metric':<30} {'Test Set':<15} {'Train Set':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Macro-averaged Precision':<30} {test_macro_precision:<15.3f} {train_macro_precision:<15.3f}\")\n",
    "print(f\"{'Macro-averaged Recall':<27}    {test_macro_recall:<15.3f} {train_macro_recall:<15.3f}\")\n",
    "print(f\"{'Macro-averaged F1':<23}        {test_macro_f1:<15.3f} {train_macro_f1:<15.3f}\")\n",
    "print(f\"{'Accuracy':<13}                  {test_accuracy:<15.3f} {train_accuracy:<15.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cabfb124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXAMPLE RULE FIRINGS (Test Set)\n",
      "================================================================================\n",
      "\n",
      "### Cause-Effect ###\n",
      "\n",
      "Text: Avian influenza is an infectious disease of birds caused by type A strains of the influenza virus.\n",
      "E1: 'influenza' | E2: 'virus'\n",
      "Rule fired: Rule Cause-Effect_LEMMA_8248: LEMMA pattern: ['cause'] (precision=0.97, support=492)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Text: Of the hundreds of strains of avian influenza A viruses, only four have caused human infections: H5N1, H7N3, H7N7, and H9N2.\n",
      "E1: 'viruses' | E2: 'infections'\n",
      "Rule fired: Rule Cause-Effect_BIGRAM_6209: BIGRAM pattern: [('have', 'cause')] (precision=1.00, support=9)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "### Component-Whole ###\n",
      "\n",
      "Text: Still further, the circuit comprises a digital adder and an analog-to-digital converter with an analog input connected to the output of the operational amplifier and a digital output connected to a first input of the digital adder.\n",
      "E1: 'circuit' | E2: 'converter'\n",
      "Rule fired: Rule Component-Whole_BIGRAM_6849: BIGRAM pattern: [('comprise', 'a')] (precision=1.00, support=8)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Text: My cat has a problem with his paw.\n",
      "E1: 'cat' | E2: 'paw'\n",
      "Rule fired: Rule Component-Whole_BIGRAM_8944: BIGRAM pattern: [('have', 'a')] (precision=0.95, support=39)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "### Content-Container ###\n",
      "\n",
      "Text: The bomb was in a suitcase loaded in Frankfurt and transferred to the doomed Boeing 747 in London.\n",
      "E1: 'bomb' | E2: 'suitcase'\n",
      "Rule fired: Rule Content-Container_BIGRAM_5744: BIGRAM pattern: [('be', 'in')] (precision=0.89, support=122)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Text: The laptop was inside a protective plastic bag made from LDPE number 4, which can be easily recycled.\n",
      "E1: 'laptop' | E2: 'plastic bag'\n",
      "Rule fired: Rule Content-Container_BIGRAM_6022: BIGRAM pattern: [('be', 'inside')] (precision=0.82, support=31)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "### Entity-Destination ###\n",
      "\n",
      "Text: The suspect dumped the dead body into a local reservoir.\n",
      "E1: 'body' | E2: 'reservoir'\n",
      "Rule fired: Rule Entity-Destination_LEMMA_1324: LEMMA pattern: ['into'] (precision=0.74, support=559)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Text: Ten million quake survivors moved into makeshift houses.\n",
      "E1: 'survivors' | E2: 'houses'\n",
      "Rule fired: Rule Entity-Destination_BIGRAM_7456: BIGRAM pattern: [('move', 'into')] (precision=0.84, support=38)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "### Entity-Origin ###\n",
      "\n",
      "Text: As I was contemplating if I had a favorite in the pink category, a gift arrived from a sweet friend.\n",
      "E1: 'gift' | E2: 'friend'\n",
      "Rule fired: Rule Entity-Origin_BIGRAM_1578: BIGRAM pattern: [('arrive', 'from')] (precision=1.00, support=15)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Text: The male took over the entire care of the young that had left the nest.\n",
      "E1: 'young' | E2: 'nest'\n",
      "Rule fired: Rule Entity-Origin_BIGRAM_9369: BIGRAM pattern: [('have', 'leave')] (precision=0.91, support=10)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Show example rule firings\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXAMPLE RULE FIRINGS (Test Set)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Group test samples by relation\n",
    "test_by_relation = defaultdict(list)\n",
    "for i, sample in enumerate(test_processed):\n",
    "    if test_predictions[i] == sample['relation'] and sample['relation'] != 'Other':\n",
    "        test_by_relation[sample['relation']].append((sample, i))\n",
    "\n",
    "# Show 1-2 examples per relation\n",
    "for relation in sorted(test_by_relation.keys())[:5]:  # First 5 relations\n",
    "    examples = test_by_relation[relation][:2]  # Up to 2 examples each\n",
    "    \n",
    "    print(f\"\\n### {relation} ###\")\n",
    "    for sample, idx in examples:\n",
    "        print(f\"\\nText: {sample['text']}\")\n",
    "        print(f\"E1: '{sample['e1_span'].text}' | E2: '{sample['e2_span'].text}'\")\n",
    "        \n",
    "        # Find the triggered rule to show its structured pattern\n",
    "        explanation = test_explanations[idx]\n",
    "        print(f\"Rule fired: {explanation}\")\n",
    "        \n",
    "        # If it's a DEP_VERB rule, show structured DependencyMatcher pattern\n",
    "        if 'DEP_VERB' in explanation:\n",
    "            # Extract rule name from explanation\n",
    "            rule_name = explanation.split(':')[0].replace('Rule ', '')\n",
    "            # Find the rule in DISCOVERED_RULES\n",
    "            for rule in DISCOVERED_RULES:\n",
    "                if rule['name'] == rule_name and rule['pattern_type'] == 'DEP_VERB':\n",
    "                    verb, e1_dep, e2_dep = rule['pattern_data']\n",
    "                    print(f\"\\n  DependencyMatcher Pattern:\")\n",
    "                    print(f\"  [\")\n",
    "                    print(f\"      {{\")\n",
    "                    print(f\"          \\\"RIGHT_ID\\\": \\\"verb\\\",\")\n",
    "                    print(f\"          \\\"RIGHT_ATTRS\\\": {{\\\"LEMMA\\\": \\\"{verb}\\\", \\\"POS\\\": \\\"VERB\\\"}}\")\n",
    "                    print(f\"      }},\")\n",
    "                    print(f\"      {{\")\n",
    "                    print(f\"          \\\"LEFT_ID\\\": \\\"verb\\\",\")\n",
    "                    print(f\"          \\\"REL_OP\\\": \\\">\\\",  # verb is head of e1\")\n",
    "                    print(f\"          \\\"RIGHT_ID\\\": \\\"e1\\\",\")\n",
    "                    print(f\"          \\\"RIGHT_ATTRS\\\": {{\\\"DEP\\\": \\\"{e1_dep}\\\"}}\")\n",
    "                    print(f\"      }},\")\n",
    "                    print(f\"      {{\")\n",
    "                    print(f\"          \\\"LEFT_ID\\\": \\\"verb\\\",\")\n",
    "                    print(f\"          \\\"REL_OP\\\": \\\">\\\",  # verb is head of e2\")\n",
    "                    print(f\"          \\\"RIGHT_ID\\\": \\\"e2\\\",\")\n",
    "                    print(f\"          \\\"RIGHT_ATTRS\\\": {{\\\"DEP\\\": \\\"{e2_dep}\\\"}}\")\n",
    "                    print(f\"      }}\")\n",
    "                    print(f\"  ]\")\n",
    "                    break\n",
    "        \n",
    "        print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c426c0bb",
   "metadata": {},
   "source": [
    "## 7. Save Predictions for Official Scorer (Optional)\n",
    "\n",
    "The files are saved for potential offline evaluation with the official Perl scorer.\n",
    "Note: The Perl scorer can be slow. Use the sklearn metrics above for quick evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b97301ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing files for official scorer...\n",
      "Saved 8000 predictions to train_predictions.txt\n",
      "Saved 8000 gold labels to train_answer_key.txt\n",
      "Saved 2717 predictions to test_predictions.txt\n",
      "Saved 2717 gold labels to test_answer_key.txt\n",
      "Saved 2717 predictions to test_predictions.txt\n",
      "Saved 2717 gold labels to test_answer_key.txt\n"
     ]
    }
   ],
   "source": [
    "def save_predictions_for_scorer(predictions, processed_data, output_file):\n",
    "    \"\"\"Save predictions in official scorer format: ID\\tRelation(e1,e2)\"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        for pred, sample in zip(predictions, processed_data):\n",
    "            sample_id = sample['id']\n",
    "            \n",
    "            # Get direction from original data (default to e1,e2)\n",
    "            direction = sample.get('direction', '') or ''\n",
    "            # Remove parentheses if they exist in direction\n",
    "            direction = direction.replace('(', '').replace(')', '')\n",
    "            if not direction:\n",
    "                direction = 'e1,e2'\n",
    "            \n",
    "            # Format: ID\\tRelation(e1,e2) - ALL relations need direction\n",
    "            f.write(f\"{sample_id}\\t{pred}({direction})\\n\")\n",
    "    \n",
    "    print(f\"Saved {len(predictions)} predictions to {output_file}\")\n",
    "\n",
    "\n",
    "def create_answer_key(processed_data, output_file):\n",
    "    \"\"\"Create answer key file from processed data in official format.\"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        for sample in processed_data:\n",
    "            sample_id = sample['id']\n",
    "            relation = sample['relation']\n",
    "            direction = sample.get('direction', '') or ''\n",
    "            # Remove parentheses if they exist in direction\n",
    "            direction = direction.replace('(', '').replace(')', '')\n",
    "            if not direction:\n",
    "                direction = 'e1,e2'\n",
    "            f.write(f\"{sample_id}\\t{relation}({direction})\\n\")\n",
    "    \n",
    "    print(f\"Saved {len(processed_data)} gold labels to {output_file}\")\n",
    "\n",
    "\n",
    "# Save predictions and answer keys\n",
    "print(\"Preparing files for official scorer...\")\n",
    "save_predictions_for_scorer(train_predictions, train_processed, 'train_predictions.txt')\n",
    "create_answer_key(train_processed, 'train_answer_key.txt')\n",
    "\n",
    "save_predictions_for_scorer(test_predictions, test_processed, 'test_predictions.txt')\n",
    "create_answer_key(test_processed, 'test_answer_key.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c34c4",
   "metadata": {},
   "source": [
    "## 8. Error Analysis\n",
    "\n",
    "Analyze misclassifications to understand system limitations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8923e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze misclassifications\n",
    "def analyze_errors(samples, predictions, true_labels, explanations, n_samples=20):\n",
    "    \"\"\"Analyze misclassified examples.\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    for i, (sample, pred, true) in enumerate(zip(samples, predictions, true_labels)):\n",
    "        if pred != true:\n",
    "            errors.append({\n",
    "                'index': i,\n",
    "                'sample': sample,\n",
    "                'predicted': pred,\n",
    "                'true': true,\n",
    "                'text': sample['text'],\n",
    "                'explanation': explanations[i]\n",
    "            })\n",
    "    \n",
    "    print(f\"Total errors: {len(errors)} / {len(samples)} ({len(errors)/len(samples)*100:.1f}%)\")\n",
    "    print(f\"\\nShowing first {min(n_samples, len(errors))} errors:\\n\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, error in enumerate(errors[:n_samples]):\n",
    "        print(f\"\\nError {i+1}:\")\n",
    "        print(f\"Text: {error['text']}\")\n",
    "        print(f\"Entity 1: {error['sample']['e1_span'].text}\")\n",
    "        print(f\"Entity 2: {error['sample']['e2_span'].text}\")\n",
    "        print(f\"True relation: {error['true']}\")\n",
    "        print(f\"Predicted: {error['predicted']}\")\n",
    "        print(f\"Rule applied: {error['explanation']}\")\n",
    "        \n",
    "        # Show between words and dependency info\n",
    "        between_words = [w['text'] for w in error['sample']['between_words']]\n",
    "        print(f\"Between words: {between_words}\")\n",
    "        \n",
    "        # Show dependency path\n",
    "        dep_path = error['sample']['dep_path']\n",
    "        if dep_path:\n",
    "            path_str = ' -> '.join([f\"{d[0]}({d[2]})\" for d in dep_path[:5]])\n",
    "            print(f\"Dependency path: {path_str}\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dc7f36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Common Misclassification Patterns:\n",
      "================================================================================\n",
      "True Label                Predicted As              Count     \n",
      "--------------------------------------------------------------------------------\n",
      "Component-Whole           Other                     195       \n",
      "Member-Collection         Other                     172       \n",
      "Product-Producer          Other                     99        \n",
      "Entity-Origin             Other                     85        \n",
      "Other                     Entity-Destination        56        \n",
      "Message-Topic             Other                     56        \n",
      "Instrument-Agency         Other                     51        \n",
      "Cause-Effect              Other                     42        \n",
      "Other                     Message-Topic             38        \n",
      "Other                     Content-Container         31        \n",
      "Other                     Instrument-Agency         26        \n",
      "Other                     Component-Whole           25        \n",
      "Product-Producer          Cause-Effect              24        \n",
      "Other                     Cause-Effect              24        \n",
      "Content-Container         Other                     23        \n"
     ]
    }
   ],
   "source": [
    "# Error distribution by relation type\n",
    "def analyze_error_patterns(samples, predictions, true_labels):\n",
    "    \"\"\"Analyze error patterns by relation type.\"\"\"\n",
    "    error_matrix = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for sample, pred, true in zip(samples, predictions, true_labels):\n",
    "        if pred != true:\n",
    "            error_matrix[true][pred] += 1\n",
    "    \n",
    "    print(\"\\nMost Common Misclassification Patterns:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'True Label':<25} {'Predicted As':<25} {'Count':<10}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Sort by count\n",
    "    all_errors = []\n",
    "    for true_label in error_matrix:\n",
    "        for pred_label in error_matrix[true_label]:\n",
    "            count = error_matrix[true_label][pred_label]\n",
    "            all_errors.append((true_label, pred_label, count))\n",
    "    \n",
    "    all_errors.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    for true_label, pred_label, count in all_errors[:15]:\n",
    "        print(f\"{true_label:<25} {pred_label:<25} {count:<10}\")\n",
    "    \n",
    "    return error_matrix\n",
    "\n",
    "error_patterns = analyze_error_patterns(test_processed, test_predictions, test_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4cdb023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing errors on test set...\n",
      "Total errors: 1302 / 2717 (47.9%)\n",
      "\n",
      "Showing first 15 errors:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Error 1:\n",
      "Text: The school master teaches the lesson with a stick.\n",
      "Entity 1: master\n",
      "Entity 2: stick\n",
      "True relation: Instrument-Agency\n",
      "Predicted: Other\n",
      "Rule applied: No high-precision rule matched; defaulting to Other.\n",
      "Between words: ['teaches', 'the', 'lesson', 'with', 'a']\n",
      "Dependency path: nsubj(master) -> ROOT(teach) -> prep(with) -> pobj(stick)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Error 2:\n",
      "Text: The ear of the African elephant is significantly larger--measuring 183 cm by 114 cm in the bush elephant.\n",
      "Entity 1: ear\n",
      "Entity 2: elephant\n",
      "True relation: Component-Whole\n",
      "Predicted: Other\n",
      "Rule applied: No high-precision rule matched; defaulting to Other.\n",
      "Between words: ['of', 'the', 'African']\n",
      "Dependency path: nsubj(ear) -> prep(of) -> pobj(elephant)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Error 3:\n",
      "Text: A child is told a lie for several years by their parents before he/she realizes that a Santa Claus does not exist.\n",
      "Entity 1: lie\n",
      "Entity 2: parents\n",
      "True relation: Product-Producer\n",
      "Predicted: Other\n",
      "Rule applied: No high-precision rule matched; defaulting to Other.\n",
      "Between words: ['for', 'several', 'years', 'by', 'their']\n",
      "Dependency path: dobj(lie) -> ROOT(tell) -> agent(by) -> pobj(parent)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Error 4:\n",
      "Text: Skype, a free software, allows a hookup of multiple computer users to join in an online conference call without incurring any telephone costs.\n",
      "Entity 1: hookup\n",
      "Entity 2: users\n",
      "True relation: Member-Collection\n",
      "Predicted: Other\n",
      "Rule applied: No high-precision rule matched; defaulting to Other.\n",
      "Between words: ['of', 'multiple', 'computer']\n",
      "Dependency path: nsubj(hookup) -> prep(of) -> pobj(user)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Error 5:\n",
      "Text: The disgusting scene was retaliation against her brother Philip who rents the room inside this apartment house on Lombard street.\n",
      "Entity 1: room\n",
      "Entity 2: house\n",
      "True relation: Component-Whole\n",
      "Predicted: Other\n",
      "Rule applied: No high-precision rule matched; defaulting to Other.\n",
      "Between words: ['inside', 'this', 'apartment']\n",
      "Dependency path: dobj(room) -> prep(inside) -> pobj(house)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Error 6:\n",
      "Text: As a landscape company in Atlanta, we know which plants thrive in this planting zone and know the optimum landscaping designs for local yards and business.\n",
      "Entity 1: landscape\n",
      "Entity 2: company\n",
      "True relation: Product-Producer\n",
      "Predicted: Other\n",
      "Rule applied: No high-precision rule matched; defaulting to Other.\n",
      "Between words: []\n",
      "Dependency path: compound(landscape) -> pobj(company)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Error 7:\n",
      "Text: Beneath this invocation there is a zoo of fearsome beasts, including several man-eaters, as well as sphinxes with lions' bodies and human heads.\n",
      "Entity 1: zoo\n",
      "Entity 2: beasts\n",
      "True relation: Member-Collection\n",
      "Predicted: Other\n",
      "Rule applied: No high-precision rule matched; defaulting to Other.\n",
      "Between words: ['of', 'fearsome']\n",
      "Dependency path: attr(zoo) -> prep(of) -> pobj(beast)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Error 8:\n",
      "Text: The song was composed for a famous Brazilian musician.\n",
      "Entity 1: song\n",
      "Entity 2: musician\n",
      "True relation: Product-Producer\n",
      "Predicted: Other\n",
      "Rule applied: No high-precision rule matched; defaulting to Other.\n",
      "Between words: ['was', 'composed', 'for', 'a', 'famous', 'Brazilian']\n",
      "Dependency path: nsubjpass(song) -> ROOT(compose) -> prep(for) -> pobj(musician)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Error 9:\n",
      "Text: I spent a year working for a software company to pay off my college loans.\n",
      "Entity 1: software\n",
      "Entity 2: company\n",
      "True relation: Product-Producer\n",
      "Predicted: Other\n",
      "Rule applied: No high-precision rule matched; defaulting to Other.\n",
      "Between words: []\n",
      "Dependency path: compound(software) -> pobj(company)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Error 10:\n",
      "Text: The captain and the crew of the Steve Irwin are grateful for the support of the City of Fremantle and Mayor Brad Pettitt for hosting the event.\n",
      "Entity 1: captain\n",
      "Entity 2: crew\n",
      "True relation: Other\n",
      "Predicted: Cause-Effect\n",
      "Rule applied: Rule Cause-Effect_BIGRAM_3904: BIGRAM pattern: [('and', 'the')] (precision=0.60, support=12)\n",
      "Between words: ['and', 'the']\n",
      "Dependency path: nsubj(captain) -> conj(crew)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Error 11:\n",
      "Text: Organic sesame oil has an anti-bacterial and anti imflammatory effect.\n",
      "Entity 1: sesame\n",
      "Entity 2: oil\n",
      "True relation: Entity-Origin\n",
      "Predicted: Component-Whole\n",
      "Rule applied: Rule Component-Whole_DEP_VERB_1865: DEP_VERB: ['have', 'nsubj', 'dobj'] (precision=0.92, support=56)\n",
      "Between words: []\n",
      "Dependency path: compound(sesame) -> nsubj(oil)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Error 12:\n",
      "Text: Mileson has sold his humble abode to a housing developer.\n",
      "Entity 1: housing\n",
      "Entity 2: developer\n",
      "True relation: Product-Producer\n",
      "Predicted: Other\n",
      "Rule applied: No high-precision rule matched; defaulting to Other.\n",
      "Between words: []\n",
      "Dependency path: compound(housing) -> pobj(developer)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Error 13:\n",
      "Text: The same effect is achieved the traditional way, with a team of workers like Keebler elves.\n",
      "Entity 1: effect\n",
      "Entity 2: way\n",
      "True relation: Cause-Effect\n",
      "Predicted: Message-Topic\n",
      "Rule applied: Rule Message-Topic_LEMMA_8959: LEMMA pattern: ['traditional'] (precision=0.67, support=2)\n",
      "Between words: ['is', 'achieved', 'the', 'traditional']\n",
      "Dependency path: nsubjpass(effect) -> ROOT(achieve) -> dobj(way)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Error 14:\n",
      "Text: He produces drawings and videos that have been shown in museums in Europe and America.\n",
      "Entity 1: drawings\n",
      "Entity 2: museums\n",
      "True relation: Other\n",
      "Predicted: Cause-Effect\n",
      "Rule applied: Rule Cause-Effect_BIGRAM_5564: BIGRAM pattern: [('that', 'have')] (precision=0.77, support=17)\n",
      "Between words: ['and', 'videos', 'that', 'have', 'been', 'shown', 'in']\n",
      "Dependency path: dobj(drawing) -> relcl(show) -> prep(in) -> pobj(museum)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Error 15:\n",
      "Text: Therefore, nowadays China is the complex mixture of different cultures from various epochs.\n",
      "Entity 1: cultures\n",
      "Entity 2: epochs\n",
      "True relation: Entity-Origin\n",
      "Predicted: Other\n",
      "Rule applied: No high-precision rule matched; defaulting to Other.\n",
      "Between words: ['from', 'various']\n",
      "Dependency path: pobj(culture) -> prep(from) -> pobj(epoch)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Analyze test set errors\n",
    "print(\"Analyzing errors on test set...\")\n",
    "test_errors = analyze_errors(test_processed, test_predictions, test_true, test_explanations, n_samples=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54cc28d",
   "metadata": {},
   "source": [
    "# Quantitative, Qualitative and Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a89081a",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "---\n",
    "<img src=\"confusion_matrix_training__rb_system.png\" alt=\"Confusion Matrix of Training Data Set\" width=\"500\" />\n",
    "\n",
    "---\n",
    "<img src=\"confusion_matrix_test__rb_system.png\" alt=\"Confusion Matrix of Test Data Set\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ae88a",
   "metadata": {},
   "source": [
    "## 9. Quantitative and Qualitative Interpretation of Results\n",
    "\n",
    "The deterministic rule-based system achieves **0.605 accuracy** on the training\n",
    "set and **0.521 accuracy** on the test set, with a **macro-F1 of 0.53** on the\n",
    "test split. This reflects a typical profile for rule-based relation extraction:\n",
    "**high precision** when rules fire, but **lower recall**, especially for relations\n",
    "without consistent surface cues.\n",
    "\n",
    "---\n",
    "\n",
    "### Precision–Recall Behaviour\n",
    "\n",
    "Because rules only fire when explicit lexical or dependency patterns appear, the\n",
    "system naturally favors **high precision** and suffers from **lower recall**:\n",
    "\n",
    "- Precision is strong across most relations (0.70–0.85) because rules are mined\n",
    "  with strict precision thresholds and ranked by reliability.\n",
    "- Recall varies widely. Many valid instances contain no trigger pattern, so the\n",
    "  classifier defaults to `\"Other\"`, lowering recall for several relations.\n",
    "- Well-marked relations (e.g., Cause-Effect, Entity-Destination) have a good\n",
    "  precision–recall balance, while ambiguous ones (Component-Whole,\n",
    "  Member-Collection) show large precision–recall gaps.\n",
    "\n",
    "This pattern is expected and confirms that deterministic rules behave as\n",
    "high-precision, low-recall classifiers.\n",
    "\n",
    "---\n",
    "\n",
    "### Strong Performing Relations\n",
    "\n",
    "Relations with stable lexical and syntactic patterns achieve the highest F1:\n",
    "\n",
    "- **Cause-Effect** (F1 ≈ 0.80): consistent verbs like *cause*, *lead to*.\n",
    "- **Content-Container** (F1 ≈ 0.69): clear markers such as *in*, *inside*, *contain*.\n",
    "- **Entity-Destination** (F1 ≈ 0.78): reliable directional cues (*to*, *into*).\n",
    "- **Message-Topic** (F1 ≈ 0.69): Topic-marking cues (*about*, *regarding*).\n",
    "\n",
    "These relations have strong, repeated indicators that rules can capture reliably.\n",
    "\n",
    "---\n",
    "\n",
    "### Moderate Performing Relations\n",
    "\n",
    "These relations have useful cues but also structural variability:\n",
    "\n",
    "- **Entity-Origin**, **Instrument-Agency**, **Product-Producer**\n",
    "\n",
    "They share patterns with other relations or appear in multiple syntactic forms,\n",
    "which reduces both precision and recall.\n",
    "\n",
    "---\n",
    "\n",
    "### Challenging Relations\n",
    "\n",
    "Some relations perform poorly due to ambiguous or sparse linguistic signals:\n",
    "\n",
    "- **Component-Whole** – overloaded prepositions (*of*, *in*, *on*) across many meanings.\n",
    "- **Member-Collection** – often requires semantic/world knowledge (e.g., *team–player*).\n",
    "- **Other** – catch-all category with inconsistent phrasing.\n",
    "\n",
    "These relations lack strong surface cues, making them inherently difficult for\n",
    "a rule-based system.\n",
    "\n",
    "---\n",
    "\n",
    "### Generalization and Overfitting\n",
    "\n",
    "The difference between **train macro-F1 (0.63)** and **test macro-F1 (0.53)**\n",
    "indicates **moderate overfitting**, expected for deterministic rules. Rule mining\n",
    "captures specific training patterns with high precision, but variations on the\n",
    "test set reduce recall.\n",
    "\n",
    "---\n",
    "\n",
    "### Overall Summary\n",
    "\n",
    "The system discovers many highly reliable rules (average precision ≈ 0.906),\n",
    "leading to strong performance on well-marked relations. Performance drops for\n",
    "relations with ambiguous or weak linguistic cues due to recall limitations.\n",
    "Overall, the results match the expected behavior of a **high-precision,\n",
    "low-recall, fully explainable decision-list classifier**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34d541",
   "metadata": {},
   "source": [
    "## Rule Diagnostics Overview\n",
    "\n",
    "<img src=\"rule_diagnostics.png\" alt=\"Rule Diagnostics Summary\" width=\"500\" />\n",
    "\n",
    "The rule-mining step generated a total of **1841 rules** across all relations,\n",
    "with an average precision of **0.868** and average support of **6.3**. This shows\n",
    "that the majority of discovered patterns are highly reliable when they appear,\n",
    "while some relations require many small, specialized rules due to high lexical\n",
    "variability (e.g., Message-Topic, Entity-Destination, Cause-Effect).\n",
    "\n",
    "Macro-averaged precision and recall reflect the typical behavior of a\n",
    "deterministic rule-based system: **precision is high**, since rules only fire\n",
    "when their patterns match exactly, but **recall is lower**, as many instances do\n",
    "not contain strong surface cues. These diagnostics complement the per-class\n",
    "evaluation and help characterize the strengths and limitations of the learned\n",
    "ruleset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103dfc9",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "<img src=\"error_analysis__most_common_missclf_patterns.png\" alt=\"Error Analysis of Rule-Based System\" width=\"500\" />\n",
    "\n",
    "The majority of misclassifications follow a consistent pattern: instances from\n",
    "several relation types fall through to the `\"Other\"` class. This reflects a\n",
    "typical limitation of deterministic rule-based systems—rules only trigger when a\n",
    "specific pattern appears, so relations with weak or highly variable surface cues\n",
    "are often missed entirely.\n",
    "\n",
    "The most common errors include:\n",
    "\n",
    "- **Component-Whole → Other** (195 cases)  \n",
    "- **Member-Collection → Other** (172 cases)  \n",
    "- **Product-Producer → Other** (99 cases)\n",
    "\n",
    "These relations rely on subtle semantic distinctions or ambiguous\n",
    "prepositions (e.g., *of*, *in*, *with*) that do not form strong, repeated\n",
    "patterns. As a result, many valid instances lack clear lexical triggers for the\n",
    "rules.\n",
    "\n",
    "Several `\"Other\"` instances are also incorrectly mapped to more specific\n",
    "relations (e.g., *Other → Entity-Destination*, *Other → Message-Topic*), showing\n",
    "that generic constructions sometimes resemble the patterns of better-defined\n",
    "relations.\n",
    "\n",
    "Overall, the misclassification patterns reinforce the precision–recall trade-off:\n",
    "the rule-based system is highly accurate when rules fire, but misses many\n",
    "instances without explicit cues, leading to lower recall for subtle or\n",
    "ambiguous relation types.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac5a80",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
